{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h2><font color=\"#004D7F\" size=5>Módulo 2: Bootstrap Aggregation</font></h2>\n",
    "\n",
    "\n",
    "<h1><font color=\"#004D7F\" size=6>8. Data Transform Bagging </font></h1>\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Manuel Castillo-Cara</font><br>\n",
    "<font color=\"#004D7F\" size=3>Aprendizaje Automático II</font><br>\n",
    "<font color=\"#004D7F\" size=3>Universidad Nacional de Educación a Distancia</font>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "\n",
    "\n",
    "* [1. Algoritmo de conjunto Data Transform Bagging](#section1)\n",
    "    * [1.1. Bagging y Random Forest Vs. Extra Trees](#section11)\n",
    "    * [1.2. Hiperparámetros de Extra Trees](#section12)\n",
    "* [2. Data Transform Ensemble para clasificación](#section2)\n",
    "    * [2.1. Dataset](#section21)\n",
    "    * [2.2. Estudio de línea base](#section22)\n",
    "    * [2.3. CART de conjunto](#section23)\n",
    "    * [2.4. Comparación con miembros contribuyentes](#section24)\n",
    "* [3. Data Transform Ensemble para regresión](#section3)\n",
    "    * [3.1. Dataset](#section31)\n",
    "    * [3.2. Estudio de línea base](#section32)\n",
    "    * [3.3. CART de conjunto](#section33)\n",
    "* [Ejercicios](#sectionEj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section0\"></a>\n",
    "# <font color=\"#004D7F\">0. Contexto</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La agregación Bootstrap (Bagging) es un conjunto en el que cada modelo se entrena en una muestra diferente del conjunto de datos de entrenamiento.\n",
    "- Un enfoque es utilizar transformaciones de datos que cambian la escala y la distribución de probabilidad de las variables de entrada como base para el entrenamiento de los miembros contribuyentes a un conjunto similar a Bagging. \n",
    "\n",
    "En este tutorial, descubrirá cómo desarrollar un conjunto de transformación de datos. Después de completar este tutorial, sabrá:\n",
    "- Las transformaciones de datos se pueden utilizar como base para un conjunto de tipo Bagging donde el mismo modelo se entrena en diferentes vistas de un conjunto de datos de entrenamiento.\n",
    "- Cómo desarrollar un conjunto de transformación de datos para clasificar y confirmar el conjunto se desempeña mejor que cualquier miembro contribuyente.\n",
    "- Cómo desarrollar y evaluar un conjunto de transformación de datos para el modelado predictivo de regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\"> 1. Algoritmo de Data Transform Bagging</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fue diseñado para usarse con árboles de decisión y cada muestra de datos se realiza utilizando el método bootstrap (selección con reemplazo), el enfoque ha generado todo un subcampo de estudio con cientos de variaciones del enfoque.\n",
    "- La idea es que pequeñas diferencias en el conjunto de datos de entrenamiento utilizado para ajustar cada modelo den como resultado pequeñas diferencias en las capacidades de los modelos.\n",
    "- Para el aprendizaje en conjunto, esto se conoce como __diversidad de miembros del conjunto__ y tiene como __objetivo descorrelacionar las predicciones__ (o errores de predicción) realizadas por cada miembro contribuyente. \n",
    "\n",
    "- Construcción de conjuntos Bagging: Se pueden crear conjuntos Bagging personalizados al cambiar el conjunto de datos usado para el aprendizaje de cada miembro contribuyente.\n",
    "- Enfoque propuesto: Aplicar diferentes transformaciones de preparación de datos a cada miembro del conjunto contribuyente.\n",
    "- Necesidad de evaluación: Se motiva la evaluación de modelos con una variedad de transformaciones de datos, como la modificación de escala y distribución de probabilidad, para determinar qué estrategias son efectivas.\n",
    "\n",
    "### _Data Transform Bagging_ o _Data Transform Ensemble_: \n",
    "Este enfoque se puede utilizar cuando se crea un conjunto de diferentes transformaciones del mismo conjunto de datos de entrenamiento, se entrena un modelo en cada una y las predicciones se combinan utilizando estadísticas simples como el promedio.\n",
    "Hay muchas transformaciones que podemos usar, pero quizás un buen punto de partida sería una selección que cambie la escala y la distribución de probabilidad, como por ejemplo:\n",
    "- Normalización (rango fijo).\n",
    "- Estandarización (media cero).\n",
    "- Estandarización robusta (robusta frente a valores atípicos).\n",
    "- Transformación de potencia (eliminar la inclinación).\n",
    "- Transformada cuantil (distribución de cambios).\n",
    "- Discretización (_k-­bins_).\n",
    "\n",
    "Resumiendo:\n",
    "- El enfoque es más eficaz cuando se usa con un modelo base que entrena diferentes o muy diferentes modelos según los efectos de la transformación de datos.\n",
    "- Cambiar la escala de la distribución es apropiado con modelos sensibles a cambios en la escala de las variables de entrada, como la regresión logística, redes neuronales, KNN y máquinas de vectores de soporte.\n",
    "- Los cambios en la distribución de probabilidad de las variables de entrada probablemente afectarían a la mayoría de los modelos de aprendizaje automático."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a> \n",
    "# <font color=\"#004D7F\"> 2. Data Transform Ensemble para clasificación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada miembro del conjunto se puede definir como un `Pipeline`, con la transformación seguida por el modelo predictivo.\n",
    "Finalmente, se puede utilizar un conjunto de votación para combinar las predicciones de cada canal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section21\"></a> \n",
    "## <font color=\"#004D7F\"> 2.1. Dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, podemos usar la función `make_classification()` para crear un problema de clasificación binaria sintética con 1000 ejemplos y 20 características de entrada. El ejemplo completo se enumera a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section22\"></a> \n",
    "## <font color=\"#004D7F\"> 2.2. Estudio de línea base</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos una línea de base:\n",
    "- Es una práctica estándar utilizar un árbol de decisión en conjuntos de Bagging, por lo que en este caso usaremos `DecisionTreeClassifier` con hiperparámetros predeterminados.\n",
    "- Evaluaremos el modelo utilizando prácticas estándar, en este caso, validación cruzada estratificada repetida de _k_ veces con 3 repeticiones y 10 pliegues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Más información sobre la clase [`DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy medio: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section23\"></a> \n",
    "## <font color=\"#004D7F\"> 2.3. CART de conjunto</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, podemos desarrollar un conjunto de árboles de decisión, cada uno de los cuales se ajusta a una transformación diferente de los datos de entrada. \n",
    "\n",
    "- Definimmos cada miembro del conjunto como un pipeline de modelado. El primer paso será la transformación de datos y el segundo será un clasificador de árbol de decisión. Por ejemplo, el Pipeline para una transformación de normalización con la clase `MinMaxScaler`.\n",
    "- Podemos repetir esto para cada transformación o configuración de transformación que queramos usar y agregar todas los pipeline del modelo a una lista.\n",
    "- La clase `VotingClassifier` se puede utilizar para combinar las predicciones de todos los modelos.\n",
    "- El conjunto de votantes simplemente promedia las predicciones hechas por los miembros contribuyentes.\n",
    "- Esta clase toma un argumento `estimators` que es una lista de tuplas donde cada tupla tiene un nombre y el modelo o proceso de modelado.\n",
    "- Para que el código sea más fácil de leer, podemos definir una función `get_ensemble()` para crear el Los miembros y los datos transforman el conjunto mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Más información sobre la clase [`VotingClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Más información sobre la clase [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Más información sobre todas las clases de de [Preprocesamiento de datos](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def get_ensemble():\n",
    "\t# definir la lista de modelos\n",
    "\t???\n",
    "\t# Normalización\n",
    "\t???\n",
    "\t???\n",
    "\t# estandardización\n",
    "\t???\n",
    "\t???\n",
    "\t# Scalamiento robust\n",
    "\t???\n",
    "\t???\n",
    "\t# Yeo-Johnson\n",
    "\t???\n",
    "\t???\n",
    "\t# Cuartiles\n",
    "\t???\n",
    "\t???\n",
    "\t# kbins\n",
    "\t???\n",
    "\t???\n",
    "\t# definimos el voto del conjunto\n",
    "\t???\n",
    "\t???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego podemos llamar a esta función y evaluar el conjunto de votación como de costumbre, tal como lo hicimos hizo para el árbol de decisión anterior. Uniendo esto, el ejemplo completo se enumera a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# obtener los ensembles\n",
    "???\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(ensemble, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy medio: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section24\"></a> \n",
    "## <font color=\"#004D7F\"> 2.4. Comparación con miembros contribuyentes</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque el conjunto tuvo un buen desempeño en comparación con un único árbol de decisión, una limitación de esta prueba es que no sabemos si el conjunto tuvo un mejor desempeño que cualquier miembro contribuyente. Esto es importante, ya que si un miembro que contribuye al conjunto se desempeña mejor, entonces sería más sencillo y fácil utilizar al propio miembro como modelo en lugar del conjunto. \n",
    "\n",
    "Podemos comprobar esto evaluando el rendimiento de cada modelo individual y comparando los resultados con el conjunto. Primero, podemos actualizar la función `get_ensemble()` para devolver una lista de modelos para evaluar compuesta por los miembros individuales del conjunto así como el conjunto mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble():\n",
    "\tmodels = list()\n",
    "\tnorm = Pipeline([('s', MinMaxScaler()), ('m', DecisionTreeClassifier())])\n",
    "\tmodels.append(('norm', norm))\n",
    "\tst = Pipeline([('s', StandardScaler()), ('m', DecisionTreeClassifier())])\n",
    "\tmodels.append(('std', st))\n",
    "\trobust = Pipeline([('s', RobustScaler()), ('m', DecisionTreeClassifier())])\n",
    "\tmodels.append(('robust', robust))\n",
    "\tpower = Pipeline([('s', PowerTransformer()), ('m', DecisionTreeClassifier())])\n",
    "\tmodels.append(('power', power))\n",
    "\tquant = Pipeline([('s', QuantileTransformer(n_quantiles=100, output_distribution='normal')), ('m', DecisionTreeClassifier())])\n",
    "\tmodels.append(('quant', quant))\n",
    "\tkbins = Pipeline([('s', KBinsDiscretizer(n_bins=20, encode='ordinal')), ('m', DecisionTreeClassifier())])\n",
    "\tmodels.append(('kbins', kbins))\n",
    "\tensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "\t# devolver la lista de nombre modelo\n",
    "\t???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos llamar a esta función y enumerar cada modelo, evaluarlo, informar el rendimiento, y almacenar los resultados.\n",
    "\n",
    "Finalmente, podemos trazar la distribución de las puntuaciones de accuracy como diagramas de caja y bigotes uno al lado del otro y comparar la distribución de las puntuaciones directamente. Visualmente, esperaríamos que la distribución de las puntuaciones del conjunto sea mayor que la de cualquier miembro individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "# obtener los modelos\n",
    "???\n",
    "# Evaluación de los modelos\n",
    "results = list()\n",
    "???\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tn_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\t# almacenar modelos\n",
    "\t???\n",
    "\tprint('>%s: %.3f (%.3f)' % (name, mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.boxplot(results, labels=[n for n,_ in models], showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a> \n",
    "# <font color=\"#004D7F\"> 3. Data Transform Ensemble para regresión</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, exploraremos el desarrollo de un conjunto de transformación de datos para un problema de modelado predictivo de regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section31\"></a> \n",
    "## <font color=\"#004D7F\"> 3.1. Dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, podemos usar la función `make_classification()` para crear un problema de clasificación binaria sintética con 1000 ejemplos y 20 características de entrada. El ejemplo completo se enumera a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section32\"></a> \n",
    "## <font color=\"#004D7F\"> 3.2. Estudio de línea base</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, podemos establecer una línea de base\n",
    "- En este caso, un `DecisionTreeRegressor`.\n",
    "- Evaluaremos el modelo utilizando prácticas estándar, en este caso, validación cruzada estratificada repetida de _k_ veces con 3 repeticiones y 10 pliegues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Más información sobre la clase [`DecisionTreeRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: La API de scikit-learn invierte el signo del MAE para transformarlo, de minimizar el error a maximizar el error negativo. Esto significa que los errores positivos de gran magnitud se convierten en grandes errores negativos (por ejemplo, 100 se convierte en -100) y un modelo perfecto no tiene ningún error con un valor de 0,0. También significa que podemos ignorar con seguridad el signo de las puntuaciones MAE medias. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section33\"></a> \n",
    "## <font color=\"#004D7F\"> 3.3. CART de conjunto</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, podemos desarrollar y evaluar el conjunto. \n",
    "- Usaremos las mismas transformaciones de datos de la sección anterior.\n",
    "- Se utilizará `VotingRegressor` para combinar las predicciones, lo cual es apropiado para problemas de regresión.\n",
    "- La función `get_ensemble()` definida a continuación crea los modelos individuales y el modelo de conjunto y combina todos los modelos como una lista de tuplas para su evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Más información sobre la clase [`VotingRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_ensemble():\n",
    "\tmodels = list()\n",
    "\tnorm = Pipeline([('s', MinMaxScaler()), ('m', DecisionTreeRegressor())])\n",
    "\tmodels.append(('norm', norm))\n",
    "\tst = Pipeline([('s', StandardScaler()), ('m', DecisionTreeRegressor())])\n",
    "\tmodels.append(('std', st))\n",
    "\trobust = Pipeline([('s', RobustScaler()), ('m', DecisionTreeRegressor())])\n",
    "\tmodels.append(('robust', robust))\n",
    "\tpower = Pipeline([('s', PowerTransformer()), ('m', DecisionTreeRegressor())])\n",
    "\tmodels.append(('power', power))\n",
    "\tquant = Pipeline([('s', QuantileTransformer(n_quantiles=100, output_distribution='normal')), ('m', DecisionTreeRegressor())])\n",
    "\tmodels.append(('quant', quant))\n",
    "\tkbins = Pipeline([('s', KBinsDiscretizer(n_bins=20, encode='ordinal')), ('m', DecisionTreeRegressor())])\n",
    "\tmodels.append(('kbins', kbins))\n",
    "    # voting\n",
    "\t???\n",
    "\t# devuelve la tupa\n",
    "\t???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego podemos llamar a esta función y evaluar cada canal de modelado contribuyente de forma independiente y comparar los resultados con el conjunto de los canales. Nuestra expectativa, como antes, es que el conjunto dé como resultado un aumento en el rendimiento con respecto a cualquier modelo individual. Si no es así, entonces se debería elegir el modelo individual de mayor rendimiento. \n",
    "\n",
    "Uniendo todo esto, a continuación se enumera el ejemplo completo para evaluar un conjunto de transformación de datos para un conjunto de datos de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "# obtener modelos\n",
    "???\n",
    "# evaluar cada modelo\n",
    "???\n",
    "???\n",
    "\tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tn_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\t# almacenar resultados\n",
    "\t???\n",
    "\tprint('>%s: %.3f (%.3f)' % (name, mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.boxplot(results, labels=[n for n,_ in models], showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sectionEj\"></a>\n",
    "<h3><font color=\"#004D7F\" size=6> <i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\" style=\"color:#113D68\"></i> Ejercicios</font></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se proponen las siguientes actividades para consolidar el aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 1</font>\n",
    "__Hiperparámetros__. Explore diferentes configuraciones que veas en la librerías vistas ya sean de Preprocesamiento de datos o propias de los algoritmos utilizados y comente los resultados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 2</font>\n",
    "__Preprocesamiento de datos__. En Scikit-learn se encuentran otras muchas clases sobre procesamiento de datos. Utilice alguna de ellas comentado su impacto y resultados al utilizarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 3</font>\n",
    "__Datasets reales__. Busque un dataset original y verdadero (que no sea sintético) y evalúe el uso de los conceptos vistos en esta unidad. Los conjuntos de datos en pueden ser obtenidos del [repositorio de aprendizaje automático de UCI](https://archive.ics.uci.edu/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 4</font>\n",
    "__Voto__. Busque otras técnicas en cuanto al algoritmo de voto y evalúe su impacto, de manera teória y práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 5</font>\n",
    "__Búsqueda de la mejor configuración__. Como se ha visto existen diferentes hiperparámetros que pueden ajustar nuestro modelo. Haga una búsqueda para un dataset real de cuales, entre un rango amplio de hiperparétros, maximizan la métrica. Puede utilizar una búsqueda aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 6</font>\n",
    "__Métodos Bagging__. Explore qué otros métodos Bagging se encuentran en la literatura y desarrolle este nuevo método a imagen y semejanza de cómo lo hemos visto, pero para un dataset real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
