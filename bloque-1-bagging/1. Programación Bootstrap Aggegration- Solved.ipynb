{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"#004D7F\" size=5>Módulo 2: Bootstrap Aggregation</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#004D7F\" size=6> 1. Programación Bootstrap Aggegration </font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Manuel Castillo-Cara</font><br>\n",
    "<font color=\"#004D7F\" size=3>Aprendizaje Automático II</font><br>\n",
    "<font color=\"#004D7F\" size=3>Universidad Nacional de Educación a Distancia</font>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "\n",
    "\n",
    "* [1. Introducción](#section1)\n",
    "   * [1.1. Algoritmo Bootstrap Aggregation](#section11)\n",
    "   * [1.2. Dataset](#section12)\n",
    "   * [1.3. Tutorial](#section13)\n",
    "* [2. Remuestreo de Bootstrap](#section2)\n",
    "* [3. Caso de estudio: dataset Sonar](#section3)\n",
    "   * [3.1. Resultados](#section31)\n",
    "   * [3.2. Comentarios finales](#section32)\n",
    "* [Ejercicios](#sectionEj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section0\"></a>\n",
    "# <font color=\"#004D7F\">0. Contexto</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los árboles de decisión son una técnica de modelado predictivo simple y poderosa, pero adolecen de una gran varianza. Esto significa que los árboles pueden obtener resultados muy diferentes con diferentes datos de entrenamiento. Una técnica para hacer que los árboles de decisión sean más robustos y lograr un mejor rendimiento se llama agregación de arranque (Bootstrap aggregation) para abreviar. En este tutorial descubrirás cómo implementar el procedimiento bootstrap con árboles de decisión desde cero con Python. Después de completar este\n",
    "tutorial, sabrá:\n",
    "- Cómo crear una muestra bootstrap de su conjunto de datos.\n",
    "- Cómo hacer predicciones con modelos bootstrap.\n",
    "- Cómo aplicar bagging a sus propios problemas de modelado predictivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\"> 1. Introducción</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta sección proporciona una breve descripción de Bootstrap Aggregation y el conjunto de datos de Sonar que se utilizarán en este tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section11\"></a>\n",
    "## <font color=\"#004D7F\"> 1.1. Algoritmo Bootstrap Aggregation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap es una muestra de un conjunto de datos con reemplazo. \n",
    "- Esto significa que se crea un nuevo conjunto de datos a partir de una muestra aleatoria de un conjunto de datos existente donde se puede seleccionar una fila determinada y agregarla más de una vez a la muestra. \n",
    "- Es un enfoque útil para estimar valores como la media de un conjunto de datos más amplio, cuando solo se dispone de un conjunto de datos limitado. \n",
    "- Al crear muestras de su conjunto de datos y estimar la media de esas muestras, puede tomar el promedio de esas estimaciones y tener una mejor idea de la verdadera media del problema subyacente.\n",
    "\n",
    "Este mismo enfoque se puede utilizar con algoritmos de aprendizaje automático que tienen una alta varianza, como los árboles de decisión (CART) presentados anteriormente. Se entrena un modelo separado en cada muestra de datos Bootstrap y el resultado promedio de esos modelos utilizados para hacer predicciones. Esta técnica se llama agregación bootstrap. \n",
    "- La varianza significa que el rendimiento de un algoritmo es sensible a los datos de entrenamiento; \n",
    "- una varianza alta sugiere que cuanto más se cambian los datos de entrenamiento, más variará el rendimiento del algoritmo.\n",
    "\n",
    "El rendimiento de los algoritmos de aprendizaje automático de alta varianza, como los árboles de decisión no\n",
    "podados, se puede mejorar entrenando muchos árboles y tomando el promedio de sus predicciones. Los resultados\n",
    "suelen ser mejores que los de un único árbol de decisión. Otro beneficio de Bootstrap, además del rendimiento\n",
    "mejorado, es que los árboles de decisión bagging no pueden adaptarse demasiado al problema. Se pueden\n",
    "seguir añadiendo árboles hasta que se alcance el máximo rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: En Scikit-learn podemos ver los diferentes parámetros que tiene [BaggingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) y [BaggingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section12\"></a>\n",
    "## <font color=\"#004D7F\"> 1.2. Dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este tutorial usaremos el conjunto de datos Sonar. \n",
    "- Este conjunto de datos implica la discriminación entre minas y rocas. \n",
    "- El desempeño de referencia sobre el problema es aproximadamente del 53%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Más información sobre el dataset [Sonar](https://archive.ics.uci.edu/dataset/151/connectionist+bench+sonar+mines+vs+rocks)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section13\"></a>\n",
    "## <font color=\"#004D7F\"> 1.3. Tutorial</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este tutorial se divide en 2 partes:\n",
    "- Remuestreo de Bootstrap.\n",
    "- Caso de estudio Sonar.\n",
    "Estos pasos proporcionan la base que necesita para implementar y aplicar bootstrap aggregation con árboles de decisión a sus propios problemas de modelado predictivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a> \n",
    "# <font color=\"#004D7F\"> 2. Remuestreo de Bootstrap</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comencemos por tener una idea clara de cómo funciona el método bootstrap. \n",
    "- Podemos crear una nueva muestra de un conjunto de datos seleccionando aleatoriamente filas del conjunto de datos y agregándolas a una nueva lista. \n",
    "- Podemos repetir esto para un número fijo de filas o hasta que el tamaño del nuevo conjunto de datos coincida con una proporción del tamaño del conjunto de datos original.\n",
    "- Podemos permitir el muestreo con reemplazo al no eliminar la fila que se seleccionó para que esté disponible para selecciones futuras. \n",
    "\n",
    "Veamos algunos detalles del código:\n",
    "- A continuación se muestra una función denominada `subsample()` que implementa este procedimiento. \n",
    "- La función `randrange()` del módulo `random` se utiliza para seleccionar un índice de fila aleatorio para agregar a la muestra cada iteración del bucle. \n",
    "- El tamaño predeterminado de la muestra es el tamaño del conjunto de datos original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of subsampling a dataste\n",
    "from random import seed\n",
    "from random import randrange\n",
    "\n",
    "# Create a random subsample from the dataset with replacement\n",
    "def subsample(dataset, ratio=1.0):\n",
    "\tsample = list()\n",
    "\tn_sample = round(len(dataset) * ratio)\n",
    "\twhile len(sample) < n_sample:\n",
    "\t\tindex = randrange(len(dataset))\n",
    "\t\tsample.append(dataset[index])\n",
    "\treturn sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos utilizar esta función para estimar la media de un conjunto de datos artificial. \n",
    "1. Primero, podemos crear un conjunto de datos con 20 filas y una sola columna de números aleatorios entre 0 y 9 y calcular el valor medio. \n",
    "2. Luego podemos hacer muestras bootstrap del conjunto de datos original, calcular la media y repetir este proceso hasta que tengamos una lista de medias. \n",
    "3. Tomar el promedio de estas medias muestrales debería darnos una estimación sólida de la media de todo el conjunto de datos.\n",
    "\n",
    "Veamos el código:\n",
    "- Cada muestra de arranque se crea como una muestra del 10% del conjunto de datos de 20 observaciones original (o 2 observaciones). \n",
    "- Luego experimentamos creando 1, 10, 100 muestras bootstrap del conjunto de datos original, calculamos su valor medio y luego promediamos todos esos valores medios estimados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Mean: 4.500\n",
      "Samples=1, Estimated Mean: 4.000\n",
      "Samples=10, Estimated Mean: 4.700\n",
      "Samples=100, Estimated Mean: 4.570\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean of a list of numbers\n",
    "def mean(numbers):\n",
    "\treturn sum(numbers) / float(len(numbers))\n",
    "\n",
    "# Test subsampling a dataset\n",
    "seed(1)\n",
    "# True mean\n",
    "dataset = [[randrange(10)] for i in range(20)]\n",
    "print('True Mean: %.3f' % mean([row[0] for row in dataset]))\n",
    "# Estimated means\n",
    "ratio = 0.10\n",
    "for size in [1, 10, 100]:\n",
    "\tsample_means = list()\n",
    "\tfor i in range(size):\n",
    "\t\tsample = subsample(dataset, ratio)\n",
    "\t\tsample_mean = mean([row[0] for row in sample])\n",
    "\t\tsample_means.append(sample_mean)\n",
    "\tprint('Samples=%d, Estimated Mean: %.3f' % (size, mean(sample_means)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ejecutar el ejemplo se imprime el valor medio original que pretendemos estimar. Luego podemos ver la media\n",
    "estimada a partir de diferentes números de muestras de arranque. Podemos ver que con 100 muestras logramos una\n",
    "buena estimación de la media\n",
    "\n",
    "En lugar de calcular el valor medio, podemos crear un modelo a partir de cada submuestra. Veamos cómo podemos combinar las predicciones de múltiples modelos bootstrap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a> \n",
    "# <font color=\"#004D7F\"> 3. Caso de estudio: dataset Sonar</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, aplicaremos el algoritmo Bagging al conjunto de datos de Sonar. \n",
    "1. Primero se carga el conjunto de datos, los valores de cadena se convierten a numéricos y la columna de salida se convierte de cadenas a valores enteros de 0 a 1. \n",
    "    - Esto se logra con las funciones auxiliares `load_csv()`, `str_column_to_float()` y `str_columna_to_int()` para cargar y preparar el conjunto de datos.\n",
    "2. Usaremos _k_-fold para estimar el rendimiento del modelo aprendido en datos invisibles. \n",
    "    - Esto significa que construiremos y evaluaremos _k_ modelos y estimaremos el rendimiento como el error medio del modelo. \n",
    "    - El Accuracy se utilizará para evaluar cada modelo. \n",
    "    - Estos comportamientos se proporcionan en las funciones `cross_validation_split()`, `accuracy_metric()`\n",
    "y `evaluate_algorithm()`.\n",
    "3. También usaremos una implementación del algoritmo CART adaptado para empaquetar con las funciones auxiliares del Capítulo 11 , incluyendo:\n",
    "    - `test split()` para dividir un conjunto de datos en grupos, \n",
    "    - `gini_index()` para evaluar un punto de división, \n",
    "    - `get_split()` para encontrar un punto de división óptimo, \n",
    "    - `to_terminal()`, `split()` y `build_tree()` se usan para crear un único árbol de decisión, \n",
    "    - `predict()` para hacer una predicción con un árbol de decisión y\n",
    "    - `subsample()` descrita en el paso anterior para hacer una submuestra del conjunto de datos de entrenamiento.\n",
    "4. Se desarrolla una nueva función denominada `bagging_predict()` que se encarga de realizar una predicción con cada árbol de decisión y combinar las predicciones en un único valor de retorno. \n",
    "    - Esto se logra seleccionando la predicción más común de la lista de predicciones realizadas por los árboles bagging.\n",
    "5. Finalmente, se desarrolla una nueva función llamada `bagging()` que es responsable de crear las muestras del conjunto de datos de entrenamiento, entrenar un árbol de decisión en cada una y luego hacer predicciones en el conjunto de test utilizando la lista de árboles bagging. \n",
    "\n",
    "El ejemplo completo se enumera a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trees: 1\n",
      "Scores: [87.8048780487805, 65.85365853658537, 65.85365853658537, 65.85365853658537, 73.17073170731707]\n",
      "Mean Accuracy: 71.707%\n",
      "Trees: 5\n",
      "Scores: [60.97560975609756, 80.48780487804879, 78.04878048780488, 82.92682926829268, 63.41463414634146]\n",
      "Mean Accuracy: 73.171%\n",
      "Trees: 10\n",
      "Scores: [60.97560975609756, 73.17073170731707, 82.92682926829268, 80.48780487804879, 68.29268292682927]\n",
      "Mean Accuracy: 73.171%\n",
      "Trees: 50\n",
      "Scores: [63.41463414634146, 75.60975609756098, 80.48780487804879, 75.60975609756098, 85.36585365853658]\n",
      "Mean Accuracy: 76.098%\n"
     ]
    }
   ],
   "source": [
    "# Bagging Algorithm on the Sonar dataset\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "\n",
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "\tdataset = list()\n",
    "\twith open(filename, 'r') as file:\n",
    "\t\tcsv_reader = reader(file)\n",
    "\t\tfor row in csv_reader:\n",
    "\t\t\tif not row:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tdataset.append(row)\n",
    "\treturn dataset\n",
    "\n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = float(row[column].strip())\n",
    "\n",
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "\tclass_values = [row[column] for row in dataset]\n",
    "\tunique = set(class_values)\n",
    "\tlookup = dict()\n",
    "\tfor i, value in enumerate(unique):\n",
    "\t\tlookup[value] = i\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = lookup[row[column]]\n",
    "\treturn lookup\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "\tdataset_split = list()\n",
    "\tdataset_copy = list(dataset)\n",
    "\tfold_size = int(len(dataset) / n_folds)\n",
    "\tfor _ in range(n_folds):\n",
    "\t\tfold = list()\n",
    "\t\twhile len(fold) < fold_size:\n",
    "\t\t\tindex = randrange(len(dataset_copy))\n",
    "\t\t\tfold.append(dataset_copy.pop(index))\n",
    "\t\tdataset_split.append(fold)\n",
    "\treturn dataset_split\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "\tcorrect = 0\n",
    "\tfor i in range(len(actual)):\n",
    "\t\tif actual[i] == predicted[i]:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn correct / float(len(actual)) * 100.0\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "\tfolds = cross_validation_split(dataset, n_folds)\n",
    "\tscores = list()\n",
    "\tfor fold in folds:\n",
    "\t\ttrain_set = list(folds)\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "\t\ttest_set = list()\n",
    "\t\tfor row in fold:\n",
    "\t\t\trow_copy = list(row)\n",
    "\t\t\ttest_set.append(row_copy)\n",
    "\t\t\trow_copy[-1] = None\n",
    "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
    "\t\tactual = [row[-1] for row in fold]\n",
    "\t\taccuracy = accuracy_metric(actual, predicted)\n",
    "\t\tscores.append(accuracy)\n",
    "\treturn scores\n",
    "\n",
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, dataset):\n",
    "\tleft, right = list(), list()\n",
    "\tfor row in dataset:\n",
    "\t\tif row[index] < value:\n",
    "\t\t\tleft.append(row)\n",
    "\t\telse:\n",
    "\t\t\tright.append(row)\n",
    "\treturn left, right\n",
    "\n",
    "# Calculate the Gini index for a split dataset\n",
    "def gini_index(groups, classes):\n",
    "\t# count all samples at split point\n",
    "\tn_instances = float(sum([len(group) for group in groups]))\n",
    "\t# sum weighted Gini index for each group\n",
    "\tgini = 0.0\n",
    "\tfor group in groups:\n",
    "\t\tsize = float(len(group))\n",
    "\t\t# avoid divide by zero\n",
    "\t\tif size == 0:\n",
    "\t\t\tcontinue\n",
    "\t\tscore = 0.0\n",
    "\t\t# score the group based on the score for each class\n",
    "\t\tfor class_val in classes:\n",
    "\t\t\tp = [row[-1] for row in group].count(class_val) / size\n",
    "\t\t\tscore += p * p\n",
    "\t\t# weight the group score by its relative size\n",
    "\t\tgini += (1.0 - score) * (size / n_instances)\n",
    "\treturn gini\n",
    "\n",
    "# Select the best split point for a dataset\n",
    "def get_split(dataset):\n",
    "\tclass_values = list(set(row[-1] for row in dataset))\n",
    "\tb_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "\tfor index in range(len(dataset[0])-1):\n",
    "\t\tfor row in dataset:\n",
    "\t\t# for i in range(len(dataset)):\n",
    "\t\t# \trow = dataset[randrange(len(dataset))]\n",
    "\t\t\tgroups = test_split(index, row[index], dataset)\n",
    "\t\t\tgini = gini_index(groups, class_values)\n",
    "\t\t\tif gini < b_score:\n",
    "\t\t\t\tb_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "\treturn {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "\n",
    "# Create a terminal node value\n",
    "def to_terminal(group):\n",
    "\toutcomes = [row[-1] for row in group]\n",
    "\treturn max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, depth):\n",
    "\tleft, right = node['groups']\n",
    "\tdel(node['groups'])\n",
    "\t# check for a no split\n",
    "\tif not left or not right:\n",
    "\t\tnode['left'] = node['right'] = to_terminal(left + right)\n",
    "\t\treturn\n",
    "\t# check for max depth\n",
    "\tif depth >= max_depth:\n",
    "\t\tnode['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "\t\treturn\n",
    "\t# process left child\n",
    "\tif len(left) <= min_size:\n",
    "\t\tnode['left'] = to_terminal(left)\n",
    "\telse:\n",
    "\t\tnode['left'] = get_split(left)\n",
    "\t\tsplit(node['left'], max_depth, min_size, depth+1)\n",
    "\t# process right child\n",
    "\tif len(right) <= min_size:\n",
    "\t\tnode['right'] = to_terminal(right)\n",
    "\telse:\n",
    "\t\tnode['right'] = get_split(right)\n",
    "\t\tsplit(node['right'], max_depth, min_size, depth+1)\n",
    "\n",
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "\troot = get_split(train)\n",
    "\tsplit(root, max_depth, min_size, 1)\n",
    "\treturn root\n",
    "\n",
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "\tif row[node['index']] < node['value']:\n",
    "\t\tif isinstance(node['left'], dict):\n",
    "\t\t\treturn predict(node['left'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['left']\n",
    "\telse:\n",
    "\t\tif isinstance(node['right'], dict):\n",
    "\t\t\treturn predict(node['right'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['right']\n",
    "\n",
    "# Create a random subsample from the dataset with replacement\n",
    "#def subsample(dataset, ratio):\n",
    "#\tsample = list()\n",
    "#\tn_sample = round(len(dataset) * ratio)\n",
    "#\twhile len(sample) < n_sample:\n",
    "#\t\tindex = randrange(len(dataset))\n",
    "#\t\tsample.append(dataset[index])\n",
    "#\treturn sample\n",
    "\n",
    "# Make a prediction with a list of bagged trees\n",
    "def bagging_predict(trees, row):\n",
    "\tpredictions = [predict(tree, row) for tree in trees]\n",
    "\treturn max(set(predictions), key=predictions.count)\n",
    "\n",
    "# Bootstrap Aggregation Algorithm\n",
    "def bagging(train, test, max_depth, min_size, sample_size, n_trees):\n",
    "\ttrees = list()\n",
    "\tfor _ in range(n_trees):\n",
    "\t\tsample = subsample(train, sample_size)\n",
    "\t\ttree = build_tree(sample, max_depth, min_size)\n",
    "\t\ttrees.append(tree)\n",
    "\tpredictions = [bagging_predict(trees, row) for row in test]\n",
    "\treturn(predictions)\n",
    "\n",
    "# Test bagging on the sonar dataset\n",
    "seed(1)\n",
    "# load and prepare data\n",
    "filename = 'data/sonar.all-data.csv'\n",
    "dataset = load_csv(filename)\n",
    "# convert string attributes to integers\n",
    "for i in range(len(dataset[0])-1):\n",
    "\tstr_column_to_float(dataset, i)\n",
    "# convert class column to integers\n",
    "str_column_to_int(dataset, len(dataset[0])-1)\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "max_depth = 6\n",
    "min_size = 2\n",
    "sample_size = 0.50\n",
    "for n_trees in [1, 5, 10, 50]:\n",
    "\tscores = evaluate_algorithm(dataset, bagging, n_folds, max_depth, min_size, sample_size, n_trees)\n",
    "\tprint('Trees: %d' % n_trees)\n",
    "\tprint('Scores: %s' % scores)\n",
    "\tprint('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section31\"></a> \n",
    "## <font color=\"#004D7F\"> 3.1. Resultados</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se utilizó un valor _k_ de 5 para la validación cruzada, dando a cada pliegue $\\frac{208}{5} = 41.6$ o justo 40 registros que se evaluarán en cada iteración.\n",
    "- Se construyeron árboles con una profundidad máxima de 6 y un número mínimo de filas de entrenamiento en cada nodo de 2. \n",
    "- Se crearon muestras del conjunto de datos de entrenamiento con un 50% del tamaño del conjunto de datos original. Esto fue para forzar cierta variedad en las submuestras del conjunto de datos utilizadas para entrenar cada árbol. \n",
    "- El valor predeterminado para el bagging es que el tamaño de los conjuntos de datos de muestra coincida con el tamaño del conjunto de datos de entrenamiento original.\n",
    "- Se evaluó una serie de 4 números diferentes de árboles para mostrar el comportamiento del algoritmo.\n",
    "- Se imprimen el accuracy de cada fold y accuracy medio de cada configuración. Podemos ver una tendencia de un ligero aumento en el rendimiento a medida que aumenta el número de árboles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section32\"></a> \n",
    "## <font color=\"#004D7F\"> 3.2. Comentarios finales</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una dificultad de este método es que aunque se construyen árboles profundos, los árboles bagging que se crean son muy similares. A su vez, las predicciones realizadas por estos árboles también son similares y disminuye la alta varianza que deseamos entre los árboles entrenados en diferentes muestras del conjunto de datos de entrenamiento .\n",
    "\n",
    "Esto se debe al algoritmo greedy utilizado en la construcción de los árboles seleccionando puntos de división iguales o similares. El tutorial intentó reinyectar esta variación restringiendo el tamaño de la muestra utilizada para entrenar cada árbol. Una técnica más sólida consiste en restringir las características que pueden evaluarse al crear cada punto de división. Este es el método utilizado en el algoritmo Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sectionEj\"></a>\n",
    "<h3><font color=\"#004D7F\" size=6> <i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\" style=\"color:#113D68\"></i> Ejercicios</font></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se proponen las siguientes actividades para consolidar el aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 1</font>\n",
    "__Ajustar el ejemplo__. Explore diferentes configuraciones para la cantidad de árboles e incluso configuraciones de árbol individuales para ver si puede mejorar aún más los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 2</font>\n",
    "__Bag de otro algoritmo__. Se pueden utilizar otros algoritmos con bagging. Por ejemplo, un algoritmo de _k_-nearest neighbor con un valor bajo de _k_ tendrá una varianza alta y es un buen candidato para el bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 3</font>\n",
    "__Problema de Regresión__. Bagging se puede utilizar con árboles de regresión. En lugar de predecir el valor de clase más común del conjunto de predicciones, puede devolver el promedio de las predicciones de los árboles bagging. Experimente con problemas de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
