{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"#004D7F\" size=5>Módulo 2: Bootstrap Aggregation</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#004D7F\" size=6> 4. Feature Selection Subspace </font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Manuel Castillo-Cara</font><br>\n",
    "<font color=\"#004D7F\" size=3>Aprendizaje Automático II</font><br>\n",
    "<font color=\"#004D7F\" size=3>Universidad Nacional de Educación a Distancia</font>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "\n",
    "\n",
    "* [1. Algoritmo de conjunto Feature Selection Subspace](#section1)\n",
    "* [2. Feature Selection Subspace: Método simple](#section2)\n",
    "    * [2.1. Estadístico ANOVA](#section21)\n",
    "    * [2.2. Información Mutua](#section22)\n",
    "    * [2.3. Selección de Características Recursivas (RFE)](#section23)\n",
    "* [3. Combined Feature Selection](#section3)\n",
    "   * [3.1. Conjunto con número fijo de características](#section31)\n",
    "   * [3.2. Conjunto con número continuo de características](#section32)\n",
    "* [Ejercicios](#sectionEj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section0\"></a>\n",
    "# <font color=\"#004D7F\">0. Contexto</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Subspace consiste en el ajuste del modelo en diferentes grupos de características de entrada (columnas) seleccionados aleatoriamente en train. \n",
    "- Feature selection son las técnicas más populares. \n",
    "\n",
    "Después de completar este tutorial, sabrá:\n",
    "- La selección de características proporciona una alternativa a Random Subspace para seleccionar grupos de entradas decaracterísticas.\n",
    "- Cómo desarrollar y evaluar conjuntos mediante técnicas de selección de elementos individuales.\n",
    "- Cómo desarrollar y evaluar conjuntos seleccionadas mediante múltiples técnicas diferentes de selección de características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\"> 1. Algoritmo de conjunto Feature Selection Subspace</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Subspace ajusta un modelo en diferentes grupos de columnas seleccionadas al azar en el conjunto de datos de entrenamiento. \n",
    "- La diferencia en la elección de las columnas de cada modelo del conjunto da como resultado una diversidad de modelos y sus predicciones. \n",
    "- Cada modelo funciona bien, aunque cada uno lo hace de manera diferente, cometiendo diferentes errores.\n",
    "- La selección de características intenta seleccionar un subconjunto de columnas que sea más relevante para la variable de destino. \n",
    "- Los enfoques populares implican el uso:\n",
    "    - De medidas estadísticas, como información mutua, y\n",
    "    - La evaluación de modelos en subconjuntos de características y la selección del subconjunto que da como resultado el modelo de mejor rendimiento, lo que se denomina eliminación recursiva de características (RFE) para abreviar.\n",
    "- La diferencia principal con Random Subspaces es que este selecciona características al azar\n",
    "- Feautre Selection Subspaces lo hace en base a un método de Feature Selection, i.e., en base a una métrica.\n",
    "\n",
    "Dos enfoques naturales incluyan:\n",
    "- __Método simple__: genera un subespacio de características para cada número de características desde 1 hasta el número de columnas, ajusta un modelo en cada una y combina sus predicciones.\n",
    "- __Múltiples métodos__: genere un subespacio de características usando múltiples métodos de selección de características diferentes, ajusta un modelo a cada uno y combinar sus predicciones.\n",
    "\n",
    "<figure><center>\n",
    "  <img src=\"data/featureSelectionSubset.png\" width=\"450\" height=\"450\" alt=\"Gráfica\">\n",
    "  <figcaption><blockquote>feature Selection Subset. Extraída de <a href=\"http://dx.doi.org/10.21203/rs.3.rs-3229911/v1\">Random Subspace Evolutionary Feature Selection for High-dimensional Data</a></blockquote></figcaption>\n",
    "</center></figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section11\"></a> \n",
    "## <font color=\"#004D7F\"> 1.1. Dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definamos un problema de prueba como base para esta exploración y establezcamos una línea de base en el rendimiento para ver si ofrece un beneficio sobre un solo modelo. Primero, podemos usar la función `make_classification()` para crear un problema de clasificación binaria sintética con 1000 ejemplos y 20 características de entrada. El ejemplo completo se enumera a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ejecución del ejemplo crea el conjunto de datos y resume la forma de los componentes de entrada y salida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section12\"></a> \n",
    "## <font color=\"#004D7F\"> 1.2. Resultado de línea base</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos una línea de base en el desempeño. Usaremos árboles de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy medio: 0.796 (0.050)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Definimos el modelo de línea base\n",
    "model = DecisionTreeClassifier()\n",
    "# método de evaulación\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluamos\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# reportamos el rendimiento\n",
    "print('Accuracy medio: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a> \n",
    "# <font color=\"#004D7F\"> 2. Feature Selection Subspace: Método simple</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la creación de un conjunto a partir de las funciones seleccionadas mediante el método Feature Selection Subspace individual. \n",
    "- Para un método de selección de características determinado, lo aplicaremos repetidamente con diferentes números de características seleccionadas para crear __múltiples subespacios de características__. \n",
    "- Luego entrenaremos __un modelo en cada uno__, en este caso, un árbol de decisión, y combinaremos las predicciones. \n",
    "- Hay muchas formas de combinar las predicciones,en este caso usaremos un conjunto de votación que se puede configurar para usar votación dura (en este caso) o blanda para la clasificación, o promediando para la regresión.\n",
    "\n",
    "El procedimiento será el siguiente:\n",
    "1. Cada modelo en el conjunto de votación será un `Pipeline` donde el primer paso es un método de selección de características, configurado para seleccionar una cantidad específica de características, seguido de un modelo clasificador de árbol de decisión. \n",
    "2. Crearemos un subespacio de selección de características para cada número de columnas en el conjunto de datos de entrada, desde 1 hasta el número de columnas. \n",
    "3. Definimos una función auxiliar llamada `get_ensemble()` que crea un conjunto de votación (`VotingClassifier`) con miembros basados en selección de características para un número determinado de características de entrada.\n",
    "    - Podemos utilizar otros métodos de selección de características diferentes al del ejemplo\n",
    "5. Se utiliza el sistema de votos mayoritarios de las predicciones realizadas por los miembros contribuyentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que estamos trabajando con un conjunto de datos de clasificación, exploraremos tres métodos de selección características diferentes:\n",
    "- Estadístico ANOVA.\n",
    "- Información mutua.\n",
    "- Selección de funciones recursivas (RFE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section21\"></a> \n",
    "## <font color=\"#004D7F\"> 2.1. Estadístico ANOVA</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Un test F, es una clase de pruebas estadísticas que calculan la relación entre valores de varianzas, como la varianza de dos muestras diferentes o la varianza explicada y no explicada mediante una prueba estadística, como ANOVA. \n",
    "- ANOVA es una prueba de hipótesis estadística paramétrica para determinar si las medias de dos o más muestras de datos (a menudo tres o más) provienen de la misma distribución o no. \n",
    "- La librería scikit-learn proporciona una implementación del ANOVA en la función `f_classif()` a través de la clase `SelectKBest`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Más información sobre la clase [`SelectKBest`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Más información sobre la función [`f_classif()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Más información sobre la clase [`VotingClassifier()`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Más información sobre la clase [`Pipeline()`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble(n_features):\n",
    "    # definimos los modelos de línea base\n",
    "    models = list()\n",
    "    # enumeramos las características en train\n",
    "    for i in range(1, n_features+1):\n",
    "        # creamos el método de feature selection\n",
    "        fs = SelectKBest(score_func=f_classif, k=i)\n",
    "        # creamos el modelo\n",
    "        model = DecisionTreeClassifier()\n",
    "        # creamos un pipeline\n",
    "        pipeline = Pipeline([('fs',fs), ('m', model)])\n",
    "        # añadimos la tupa en la lista de modelos para voting\n",
    "        models.append((str(i), pipeline))\n",
    "    # definimos el modelo Voting\n",
    "    ensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy medio: 0.830 (0.046)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "# obtenemos los modelos de conjunto y le pasamos el número de características\n",
    "ensemble = get_ensemble(X.shape[1])\n",
    "# evaluamos el modelo\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(ensemble, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy medio: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ejecución del ejemplo informa el accuracy de la media y la desviación estándar del modelo.\n",
    "\n",
    "En este caso, podemos ver un aumento en el rendimiento con respecto a un solo modelo que logró un accuracy de aproximadamente 79,4% a aproximadamente 83,2% utilizando un conjunto de modelos sobre características seleccionadas por la estadística ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section22\"></a> \n",
    "## <font color=\"#004D7F\"> 2.2. Información Mutua</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La información mutua del campo de la teoría de la información es la aplicación de la ganancia de información (normalmente utilizada en la construcción de árboles de decisión) a la selección de características. \n",
    "- La información mutua se calcula entre dos variables y mide la reducción de la incertidumbre de una variable dado un valor conocido de la otra variable. \n",
    "- Scikit-learn proporciona una implementación de información mutua para la selección de características a través de la función `mutual_info_classif()` en la clase `SelectKBest`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Más información sobre la función [`mutual_info_classif()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "def get_ensemble(n_features):\n",
    "    models = list()\n",
    "    for i in range(1, n_features+1):\n",
    "        # creamos el método de feature selection\n",
    "        fs = SelectKBest(score_func=mutual_info_classif, k=i)\n",
    "        # creamos el modelo\n",
    "        model = DecisionTreeClassifier()\n",
    "        pipe = Pipeline([('fs', fs), ('m', model)])\n",
    "        models.append((str(i),pipe))\n",
    "    ensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy medio: 0.830 (0.042)\n"
     ]
    }
   ],
   "source": [
    "ensemble = get_ensemble(X.shape[1])\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(ensemble, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy medio: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section23\"></a> \n",
    "## <font color=\"#004D7F\"> 2.3. Selección de Características Recursivas (RFE)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La eliminación recursiva de funciones (RFE) busca un subconjunto de funciones comenzando con todas las funciones en el conjunto de datos de entrenamiento y eliminando funciones exitosamente hasta que quede el número deseado. \n",
    "- RFE está disponible a través de la clase `RFE` en Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Más información sobre la clase [`RFE`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "def get_ensemble(n_features):\n",
    "    models = list()\n",
    "    for i in range(1, n_features+1):\n",
    "        # creamos el método de feature selection\n",
    "        fs = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=i)\n",
    "        # creamos el modelo\n",
    "        model = DecisionTreeClassifier()\n",
    "        pipe = Pipeline([('fs', fs), ('m', model)])\n",
    "        models.append((str(i),pipe))\n",
    "    ensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy medio: 0.827 (0.042)\n"
     ]
    }
   ],
   "source": [
    "ensemble = get_ensemble(X.shape[1])\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(ensemble, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy medio: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a> \n",
    "# <font color=\"#004D7F\"> 3. Combined Feature Selection</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hasta ahora hemos visto un solo modelo utilizando un método de selección de características únicas como base de una predicción conjunta para un conjunto de datos. \n",
    "- Esperaríamos que las predicciones entre muchos de los miembros del conjunto estuvieran correlacionadas. \n",
    "- Esto podría solucionarse utilizando diferentes números de características en lugar de un número contiguo de características de 1 al número de columnas. \n",
    "\n",
    "Un enfoque alternativo para introducir diversidad es seleccionar subespacios de características utilizando diferentes métodos de selección de características. Exploraremos dos versiones de este enfoque. \n",
    "1. Con el primero, seleccionaremos la misma cantidad de características de cada método, y \n",
    "2. Con el segundo, seleccionaremos una cantidad contigua de características de 1 a la cantidad de columnas para múltiples métodos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section31\"></a> \n",
    "## <font color=\"#004D7F\"> 3.1. Conjunto con número fijo de características</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Seleccionaremos una cantidad arbitraria de características.\n",
    "2. Usaremos cada uno de los tres métodos de selección de características para seleccionar un subespacio de características.\n",
    "3. Ajustaremos un modelo de cada uno y los usaremos como base para un conjunto de votación. Implemetaresmos la función `get_ensemble()`.\n",
    "4. Esperamos que las características seleccionadas por cada método sean lo suficientemente diferentes para dar como resultado un conjunto eficaz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble(n_features):\n",
    "    models = list()\n",
    "    # miembros ANOVA\n",
    "    fs = SelectKBest(score_func=f_classif, k=n_features)\n",
    "    anova = Pipeline([('fs', fs), ('m', DecisionTreeClassifier())])\n",
    "    models.append(('anova', anova))\n",
    "    # Información mútua\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k=n_features)\n",
    "    mutual = Pipeline([('fs', fs), ('m', DecisionTreeClassifier())])\n",
    "    models.append(('mutual', mutual))\n",
    "    # RFE\n",
    "    fs = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=n_features)\n",
    "    rfe = Pipeline([('fs', fs), ('m', DecisionTreeClassifier())])\n",
    "    models.append(('rfe', rfe))\n",
    "    # definimos Votingdefine the voting ensemble\n",
    "    ensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy medio: 0.838 (0.039)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "\n",
    "ensemble = get_ensemble(12)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(ensemble, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy medio: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section311\"></a> \n",
    "### <font color=\"#004D7F\"> 3.1.1. Comparación con cada modelo individualmente</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una comparación más justa podría ser comparar este resultado con cada modelo individual que comprende el conjunto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "def get_ensemble(n_features):\n",
    "    models, names = list(), list()\n",
    "    # ANOVA\n",
    "    fs = SelectKBest(score_func=f_classif, k=n_features)\n",
    "    anova = Pipeline([('fs', fs), ('m', DecisionTreeClassifier())])\n",
    "    models.append(('anova', anova))\n",
    "    names.append('anova')\n",
    "    # Información mutua\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k=n_features)\n",
    "    mutinfo = Pipeline([('fs', fs), ('m', DecisionTreeClassifier())])\n",
    "    models.append(('mutinfo', mutinfo))\n",
    "    names.append('mutinfo')\n",
    "    # RFE\n",
    "    fs = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=n_features)\n",
    "    rfe = Pipeline([('fs', fs), ('m', DecisionTreeClassifier())])\n",
    "    models.append(('rfe', rfe))\n",
    "    names.append('rfe')\n",
    "    ensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "    names.append('ensemble')\n",
    "    return names, [anova, mutinfo, rfe, ensemble]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">anova: 0.817 (0.039)\n",
      ">mutinfo: 0.809 (0.040)\n",
      ">rfe: 0.829 (0.038)\n",
      ">ensemble: 0.841 (0.039)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "\n",
    "names, models = get_ensemble(15)\n",
    "# evaluar cada modelo\n",
    "results = list()\n",
    "for model, name in zip(models, names):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    #Almacenar resultados\n",
    "    results.append(n_scores)\n",
    "    print('>%s: %.3f (%.3f)' % (name, mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section32\"></a> \n",
    "## <font color=\"#004D7F\"> 3.2. Conjunto con número continuo de características</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso seleccionaremos subespacios como hicimos en la sección anterior desde 1 hasta el número de columnas del conjunto de datos, aunque en este caso repetiremos el proceso con cada método de selección de características.\n",
    "\n",
    "Esperamos que la diversidad de las características seleccionadas a través de los métodos de selección de características resulte en un aumento adicional en el rendimiento del conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble(n_features_start, n_features_end):\n",
    "    models = list()\n",
    "    for i in range(n_features_start, n_features_end+1):\n",
    "        # anova \n",
    "        fs = SelectKBest(score_func=f_classif, k=i)\n",
    "        anova = Pipeline([('fs', fs), ('m', DecisionTreeClassifier())])\n",
    "        models.append(('anova'+str(i), anova))\n",
    "        # mutual information \n",
    "        fs = SelectKBest(score_func=mutual_info_classif, k=i)\n",
    "        mutinfo = Pipeline([('fs', fs), ('m', DecisionTreeClassifier())])\n",
    "        models.append(('mutinfo'+str(i), mutinfo))\n",
    "        # RFE\n",
    "        fs = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=i)\n",
    "        rfe = Pipeline([('fs', fs), ('m', DecisionTreeClassifier())])\n",
    "        models.append(('rfe'+str(i), rfe))\n",
    "    ensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy medio: 0.840 (0.039)\n"
     ]
    }
   ],
   "source": [
    "get_ensemble(4, 16)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(ensemble, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy medio: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sectionEj\"></a>\n",
    "<h3><font color=\"#004D7F\" size=6> <i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\" style=\"color:#113D68\"></i> Ejercicios</font></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se proponen las siguientes actividades para consolidar el aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 1</font>\n",
    "__Hiperparámtros__. Explore diferentes configuraciones para la cantidad de árboles e incluso configuraciones de árbol individuales para ver si puede mejorar aún más los resultados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 2</font>\n",
    "__Problema de Regresión__. Esté tipo de métodos se puede utilizar con árboles de regresión, desarrolle este concepto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 3</font>\n",
    "__Datasets reales__. Busque un dataset original y verdadero (que no sea sintético) y evalúe el uso de los conceptos vistos en esta unidad. Los conjuntos de datos en pueden ser obtenidos del [repositorio de aprendizaje automático de UCI](https://archive.ics.uci.edu/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 4</font>\n",
    "__Feature Selection__. En este ejemplo hemos desarrollado estos conceptos con 3 métodos de selección de características. Existen muchos más, busque información sobre ellos y evalúe la opción de utilizar otros en un ejemplo como el realizado en esta unidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 5</font>\n",
    "__Método múltiple__. En este ejemplo hemos desarrollado resolver este problema con el método simple. Existe el método múltiple, busque información sobre ello y evalúe la opción de utilizarlo en un ejemplo como el realizado en esta unidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 6</font>\n",
    "__Métodos de Feature selection__. En el punto 2 se ha utilizado la clase `SelectKBest`. Evalúe 3 métodos diferentes y compruebe quién tiene mejor comportamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 7</font>\n",
    "__Búsqueda de la mejor configuración__. Como se ha visto existen diferentes hiperparámetros que pueden ajustar nuestro modelo. Haga una búsqueda para un dataset real de cuales, entre un rango amplio de hiperparétros, maximizan la métrica. Puede utilizar una búsqueda aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
