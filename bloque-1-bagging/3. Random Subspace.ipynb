{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"#004D7F\" size=5>Módulo 2: Bootstrap Aggregation</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#004D7F\" size=6> 3. Random Subspace Ensemble </font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Manuel Castillo-Cara</font><br>\n",
    "<font color=\"#004D7F\" size=3>Aprendizaje Automático II</font><br>\n",
    "<font color=\"#004D7F\" size=3>Universidad Nacional de Educación a Distancia</font>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "\n",
    "\n",
    "* [1. Algoritmo de conjunto Random Subspace](#section1)\n",
    "* [2. Random Subspace según el tipo de problema](#section2)\n",
    "    * [2.1. Random Subspace para Clasificación](#section21)\n",
    "    * [2.2. Random Subspace para Regresión](#section22)\n",
    "* [3. Hiperparámetros de Random Subspace](#section3)\n",
    "   * [3.1. Número de árboles](#section31)\n",
    "   * [3.2. Número de características](#section32)\n",
    "   * [3.3. Algoritmo alternativo](#section33)\n",
    "* [Ejercicios](#sectionEj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section0\"></a>\n",
    "# <font color=\"#004D7F\">0. Contexto</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Subspace Ensemble es un algoritmo de aprendizaje automático que combina las predicciones de múltiples árboles de decisión entrenados en diferentes subconjuntos de columnas en el conjunto de datos de entrenamiento. Variar aleatoriamente las columnas utilizadas para entrenar a cada miembro contribuyente del conjunto tiene el efecto de introducir diversidad en el conjunto y, a su vez, puede mejorar el rendimiento respecto al uso de un único árbol de decisión. Por tanto, estudiaremos en este tutorial:\n",
    "- Random Subspace se crean a partir de árboles de decisión que se ajustan a diferentes muestras de características (columnas) en el conjunto de datos de entrenamiento.\n",
    "- Cómo utilizar Random Subspace para clasificación y regresión con Scikit-learn.\n",
    "- Cómo explorar el efecto de los hiperparámetros de Random Subspace en el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\"> 1. Algoritmo de conjunto Random Subspace</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un problema de modelado predictivo consta de una o más variables de entrada y una variable objetivo. Podemos considerar que todas las características de entrada juntas definen un espacio vectorial de _n_ dimensiones, donde _n_ es el número de características de entrada y cada ejemplo (fila de datos de entrada) es un punto en el espacio de características. \n",
    "\n",
    "Esta es una conceptualización común en el aprendizaje automático y, a medida que los espacios de características de entrada se hacen más grandes, la distancia entre puntos en el espacio aumenta, lo que se conoce generalmente como la __maldición de la dimensionalidad__. Por lo tanto, \n",
    "- Un subconjunto de características de entrada puede considerarse como un subconjunto del espacio de características de entrada, o un subespacio.\n",
    "- Seleccionar características es una forma de definir un subespacio del espacio de características de entrada. \n",
    "    - Por ejemplo, la selección de características se refiere a un intento de reducir el número de dimensiones del espacio de características de entrada seleccionando un subconjunto de características para conservar o un subconjunto de características para eliminar, a menudo en función de su relación con la variable objetivo. \n",
    "- Alternativamente, podemos seleccionar subconjuntos aleatorios de características de entrada para definir subespacios aleatorios. \n",
    "\n",
    "Esto se puede utilizar como base para un algoritmo de aprendizaje conjunto, donde se puede ajustar un modelo a cada subespacio aleatorio de características. Esto se conoce como __Random Subspace__. \n",
    "\n",
    "Algunas consejos sobre Random Subspace:\n",
    "- Se puede utilizar con cualquier algoritmo de aprendizaje automático, aunque es adecuado para modelos que son sensibles a grandes cambios en las características de entrada, como árboles de decisión y KNN. \n",
    "- Es apropiado para conjuntos de datos que tienen una gran cantidad de características de entrada, ya que puede generar un buen rendimiento con buena eficiencia. \n",
    "- Si el conjunto de datos contiene muchas características de entrada irrelevantes, puede ser mejor utilizar la selección de características como técnica de preparación de datos, ya que la prevalencia de características irrelevantes en los subespacios puede perjudicar el rendimiento del conjunto.\n",
    "\n",
    "<figure><center>\n",
    "  <img src=\"data/randomSubspaces.jpg\" width=\"550\" height=\"550\" alt=\"Gráfica\">\n",
    "  <figcaption><blockquote>Random Subspace. Extraída de <a href=\"http://dx.doi.org/10.1007/s00477-022-02277-0\">Drought indicator analysis and forecasting using data driven models: case study in Jaisalmer, India</a></blockquote></figcaption>\n",
    "</center></figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a> \n",
    "# <font color=\"#004D7F\"> 2. Random Subspace según el tipo de problema</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos implementar el conjunto de Random Subspace usando Bagging en Scikit-learn. \n",
    "- Bagging se proporciona a través de las clases `BaggingRegressor` y `BaggingClassifier`. \n",
    "- Podemos configurar Bagging para que sea un conjunto de subespacio aleatorio estableciendo el argumento `bootstrap = False` para desactivar el muestreo de las filas del conjunto de datos de entrenamiento y\n",
    "- Establecer el número máximo de características en un valor determinado mediante el argumento `max_features` . \n",
    "- El modelo predeterminado para Bagging es un árbol de decisión, pero se puede cambiar a cualquier modelo que queramos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section21\"></a> \n",
    "## <font color=\"#004D7F\"> 2.1. Random Subspace para Clasificación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, veremos el uso de Random Subspaces para un problema de clasificación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section211\"></a> \n",
    "### <font color=\"#004D7F\"> 2.1.1. Dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, podemos usar la función `make_classification()` para crear un problema de clasificación binaria sintética con 1000 ejemplos y 20 características de entrada. El ejemplo completo se enumera a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section212\"></a> \n",
    "### <font color=\"#004D7F\"> 2.1.2. Evaluación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, podemos evaluar un algoritmo Random Subspaces en este conjunto de datos. \n",
    "- Evaluaremos el modelo mediante validación cruzada estratificada repetida de _k_ veces, con 3 repeticiones y 10 pliegues. \n",
    "- Informaremos la media y la desviación estándar del accuracy del modelo en todas las repeticiones y pliegues.\n",
    "\n",
    "A continuación, podemos configurar un modelo Bagging para que sea un Random Subspace para árboles de decisión en este conjunto de datos. \n",
    "- Cada modelo se ajustará a un subespacio aleatorio de 10 características de entrada, elegidas arbitrariamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Más información sobre la clase [`BaggingClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy medio: 0.856 (0.043)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# definir el modelo de conjunto de subespacios aleatorios\n",
    "model = BaggingClassifier(bootstrap=False, max_features=10, n_jobs=-1)\n",
    "# definir el método de evaluación\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluar el modelo en el conjunto de datos\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# resumir la precisión\n",
    "print('Accuracy medio: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section22\"></a> \n",
    "## <font color=\"#004D7F\"> 2.2. Random Subspace para Regresión</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, veremos el uso de Random Subspace para un problema de regresión. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section221\"></a> \n",
    "### <font color=\"#004D7F\"> 2.2.1. Dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, podemos usar la función `make_classification()` para crear un problema de regresión sintética con 1000 ejemplos y 20 características de entrada. El ejemplo completo se enumera a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=5)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section222\"></a> \n",
    "### <font color=\"#004D7F\"> 2.2.2. Evaluación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación\n",
    "- Evaluaremos el modelo mediante validación cruzada estratificada repetida de _k_ veces, con 3 repeticiones y 10 pliegues. \n",
    "- Informaremos el error absoluto medio (MAE) del modelo en todas las repeticiones y pliegues.\n",
    "\n",
    "Podemos evaluar Random Subspace mediante Bagging de este conjunto de datos. \n",
    "- Como antes, debemos configurar Bagging para usar todas las filas del conjunto de datos de entrenamiento y\n",
    "- Especificar la cantidad de funciones de entrada para seleccionar aleatoriamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Más información sobre la clase [`BaggingRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html#sklearn.ensemble.BaggingRegressor)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -116.171 (12.729)\n"
     ]
    }
   ],
   "source": [
    "# evaluate random subspace ensemble via bagging for regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "# definir el modelo de conjunto de subespacios aleatorios\n",
    "model = BaggingRegressor(bootstrap=False, max_features=10, n_jobs=-1)\n",
    "# definir el método de evaluación\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluar el modelo en el conjunto de datos\n",
    "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# resumir la precisión\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: La API de scikit-learn invierte el signo del MAE para transformarlo, de minimizar el error a maximizar el error negativo. Esto significa que los errores positivos de gran magnitud se convierten en grandes errores negativos (por ejemplo, 100 se convierte en -100) y un modelo perfecto no tiene ningún error con un valor de 0,0. También significa que podemos ignorar con seguridad el signo de las puntuaciones MAE medias. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a> \n",
    "# <font color=\"#004D7F\"> 3. Hiperparámetros de Random Subspace</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, analizaremos más de cerca algunos de los hiperparámetros que debería considerar ajustar para el conjunto Random Subspace y su efecto en el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section31\"></a> \n",
    "## <font color=\"#004D7F\"> 3.1. Número de árboles</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un hiperparámetro importante para el algoritmo Random Subspace es la cantidad de árboles de decisión utilizados en el conjunto. \n",
    "- Más árboles estabilizarán la varianza del modelo, contrarrestando el efecto de la cantidad de características seleccionadas por cada árbol que introduce diversidad.\n",
    "- El número de árboles se puede establecer mediante el argumento `n_estimators` y el valor predeterminado es 10.\n",
    "- El siguiente ejemplo explora el efecto de la cantidad de árboles con valores entre 10 y 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtener una lista de modelos para evaluar\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    # definir el número de árboles a considerar\n",
    "    n_trees = [1, 10, 50, 100, 500, 1000]\n",
    "    for n in n_trees:\n",
    "        models[str(n)] = BaggingClassifier(n_estimators=n)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluar un modelo determinado mediante validación cruzada\n",
    "def evaluate_model(model, X, y):\n",
    "    # definir el procedimiento de evaluación\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # evaluar el modelo y recopilar los resultados\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.786 (0.040)\n",
      ">10 0.852 (0.039)\n",
      ">50 0.874 (0.041)\n",
      ">100 0.881 (0.034)\n",
      ">500 0.885 (0.035)\n",
      ">1000 0.886 (0.037)\n"
     ]
    }
   ],
   "source": [
    "# definir dataset\n",
    "X, y = get_dataset()\n",
    "# obtener los modelos para evaluar\n",
    "models = get_models()\n",
    "# evaluar los modelos y almacenar los resultados\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    # evaluar el modelo\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    # almacenar los resultados\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    # resumir el progreso\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section32\"></a> \n",
    "## <font color=\"#004D7F\"> 3.2. Número de características</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El número de características seleccionadas para cada subespacio aleatorio controla la diversidad del conjunto. \n",
    "- Menos características significan más diversidad, mientras que más características significan menos diversidad.\n",
    "- Más diversidad puede requerir más árboles para reducir la varianza de las predicciones realizadas por el modelo.\n",
    "- El número de caracterśiticas utilizadas para ajustar cada árbol de decisión se establece mediante el argumento `max_features`. \n",
    "- El siguiente ejemplo varía el valor de 1 a 20 con un número fijo de árboles en el conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtener una lista de modelos para evaluar\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    # evaluar las características de 1 a 20\n",
    "    for n in range(1,21):\n",
    "        models[str(n)] = BaggingClassifier(max_features=n, bootstrap=False, n_jobs=-1)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.566 (0.055)\n",
      ">2 0.659 (0.059)\n",
      ">3 0.725 (0.043)\n",
      ">4 0.780 (0.038)\n",
      ">5 0.811 (0.036)\n",
      ">6 0.844 (0.043)\n",
      ">7 0.848 (0.029)\n",
      ">8 0.851 (0.042)\n",
      ">9 0.854 (0.037)\n",
      ">10 0.852 (0.039)\n",
      ">11 0.863 (0.034)\n",
      ">12 0.861 (0.037)\n",
      ">13 0.851 (0.040)\n",
      ">14 0.859 (0.033)\n",
      ">15 0.858 (0.043)\n",
      ">16 0.846 (0.039)\n",
      ">17 0.835 (0.043)\n",
      ">18 0.831 (0.042)\n",
      ">19 0.812 (0.045)\n",
      ">20 0.804 (0.049)\n"
     ]
    }
   ],
   "source": [
    "# definir dataset\n",
    "X, y = get_dataset()\n",
    "# obtener los modelos para evaluar\n",
    "models = get_models()\n",
    "# evaluar los modelos y almacenar los resultados\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    # evaluar el modelo\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    # almacenar los resultados\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    # resum\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAdl0lEQVR4nO3df5Ac5X3n8fdXKyGBZWAXCceWMOJcmFtOF4g9JvZFxpYJDvgcOMOFQyEVMBsouYLOPxIMuSVGKtVWOTHcj1JIpmSWy1WcLLEFSDhl8+N8MspeGZuVLAmJRfYaCMhgNAIZHcgSg+Z7f0yvmB3Nr+7p3el99vOqmtqZ6X6e/k5vz7effrrnaXN3RERk+pvV6QBERCQdSugiIoFQQhcRCYQSuohIIJTQRUQCMbtTC16wYIEvWbKkU4sXEZmWtm7dut/dF9aa1rGEvmTJEkZGRjq1eBGRacnM/qXeNHW5iIgEQgldRCQQSugiIoFQQhcRCYQSuohIIJTQRUQCoYQuIhIIJXQRkUB07IdFMjXM7Lj3ZuoY+FlZF1mJQ8KjFnrg3P1Ysqh8HsfQ0BBLly6lq6uLpUuXMjQ0lHaYUyKNdRFSHBIetdCloaGhIfr7+xkcHGTZsmUMDw/T19cHwIoVKzocnYhUUgtdGhoYGGBwcJDly5czZ84cli9fzuDgIAMDA50OTUSqWKcO93K5nGtwrqljZokO7bu6ujh8+DBz5sw59l6xWGTevHkcPXo01vKrxYmnVvm4dVTWlXS7T7P/u504skDnAjrDzLa6e67WNLXQpaHe3l6Gh4cnvDc8PExvb2+setrtN65VvhPJQ/3fb9O6yB4ldGmov7+fvr4+Nm/eTLFYZPPmzfT19dHf39/p0ESkik6KSkPjJz5XrVrF6Ogovb29DAwM6ISoSAapD32GyEp/bbtxpPE5pnsdaZ5PSENWzknMFI360NVCF5lmxhNeVnbS7Qjps2SB+tBFRAKhhC4iEgh1uYjMQOq7DlNLLXQzu8TM9pjZmJndWmN6t5k9YGY7zexHZrY0/VBFJC26hjxMTRO6mXUBdwGXAucCK8zs3KrZ/guw3d1/HfhD4H+kHaiIiDTWSgv9AmDM3Z9x9zeBe4HLq+Y5F/gegLs/DSwxs3elGqmIiDTUSkJfBLxQ8Xpv9F6lHcAVAGZ2AXAmsLi6IjO70cxGzGykUCgki1hEJGJmNR/t1tEJacTRSkKvVWt1h9tXgW4z2w6sAn4MvHVcIff17p5z99zChQvjxioiMkEaY/xk5XxCGnG0cpXLXuCMiteLgRerAjkIfBbAyruVZ6OHiIhMkVZa6E8AZ5vZWWZ2AnA18GDlDGZ2ajQN4I+ALVGSFxGRKdI0obv7W8BNwMPAKPBNd99tZivNbGU0Wy+w28yepnw1zOcnK2CZelnpY+yknp6e4z5/5euenp4ORzh1tC6yq6UfFrn7d4DvVL2Xr3j+A+DsdEOTrNB4G3DgwIGGn72VnVxPTw8HDhyoW667u5tXX301eZAtSCOGNNaFTA79UlRkimQhEWYhBpk8GstFRCQQSugZ1s41tqH0czb7HK18Fq2LbKn+HNP5f5I16nLJsMpD47j911k5tG63z7bZ56iuL0kd06WbIY11kQWhfI4sUkKXSRVKMhWZDtTlIiISCLXQRVrgt58Mq08BoNA1i5sXLuCOwn4WHC29PV1mrKyML68WukgLbM1BWP0arH6N/MVfYtuJJ5K/+E+OvWdr4v0wunCowHUPXcf+X+2fpIhlKmVlPBgldJEYCocKbBrbhONsHNuYOCHnd+bZ9vI28jvyzWeeJGnsVLRjyhYldJEY8jvzlLzczVLyUqKEnNZOoV1p7FSysGOStymhy7TR6dbgeCIulooAFEvFRAk5jZ1Cu9LYqWRlxyRvU0KXutL+QU67CTlpa/DYCc3Vp1BY2811+bPZv7b72HutntCsTMTj4iRkv/1kCmu72TR678SdwugQ+9d2xzqxmnRdjq+L/OCHKBUPlz9D8TD5u3Mtr4s06miXfnBWmxK61DV+Dbm7s++NfVz73WspHCoce6/6B0PNtHN43k5rMK0Tmjv27TiWiMcVS0W279vechz5i79EafbcCe+XZs8lf/GfxDqxmnRd2pqDFL48xqbuBRRnlZNYcZaxsXsB+2/5WUsxpFFHuyq3zXqPZttnszribt9ZoMsWpSWVCeS2D9/Wcrnx1lyhaxabFr8HnzWLjaNDrHz0ThYcLSVqHY+3iuPEAcfvFFaet5IFJy5oufyGyzbUnWY1b+x1vHZ2Cs3W5bF5mmj3SCOtOsYVDhW4ecvN3PGxO2L9P+R4aqHPAO12daTROq5smY63SFttHYfUd73hsg08ee2Txz0a7SzGNVuXra7Pdo800qpjnE6spsc6db1kLpfzkZGRjix7Ooo7lkvl/GsfX8u39nyLq8656lirtqX6oh/SrD2tmwfmz6c4y5hTcq54/XVueyU6HF39WtM49r2xj0vvv5QjR48ce39u11weuvIhFp60sHEcq0+ZsPxxceJoOwaaD1HQyjjizdZ5K9MbfY4FJy5IZRmtrIu0llE4VDj2edL8HGnHWU+tsYoqNdsumpWvVYeZbXX3XK151UIPXLut6zT6Sts5PLc1B9lxZm5CMh+PY/uZuZZbpW2f0KzqX61+b7JvTDEuza6OLMjCUVM72u2HT+NcQCX1oQeu3b7nNBJIu4fnrXRHTHYMWRHC56g+F1CcVW5Xjl/xs/LRO5ueC6gciqHhPDOMulymiSRdLml0M1y56Ur2HNhz3LRzus/hvsvvy8Rh71QsI60yjTQ7PM/KukhrGWsfX8sDP31gwg5qzqw5XHH2Ffz5R/48VrdNrZOq02ldxFlGoy4XtdAnUacH7EmjdZ3GlR1SVv2/n8n3aIX0jjaSXoFVKZQrbZTQJ1HSmyvXO1ES92a+IRyeS7jSaCy0eynquDR2ClmghJ5BadzRxW8/GbY9Wnvis8/DDOxflPBk4fcJWaKEHihbc7B5393qqYtHJG31fp8QNyGnsVPICl22KA3Vu1G1mdHd3T0ldTQqHycOKQtlXWZpbJ2sUEKXutK49rrdOpqVn8prwEOQlevp05ClsXWyQl0uIjIt6fcJx1NClxmh0Unk6dTN0Mq17NK60C7LVUKvo9PXkFdKeo1sKEmsXaFc/x3K54B0dkxZ2Lll7ebh6kOvo1YfY6vSHjg/yWh0IfWVSlhqjVdS/f50ObeS9s3D26WEPgnSHDhft/kSyb6sfE+V0DNuuo9GJ2EK5dLHtKT1PW333gVK6Bl0bDS6jFwjW6vrSGaukLrz0tgxpXUDFmj/Zh8tJXQzu8TM9pjZmJndWmP6KWb2bTPbYWa7zeyziaIRoPadacZ14hrZen2eItNZWjumtMaoT6PbpmlCN7Mu4C7gUuBcYIWZnVs12x8DT7n7ecDHgTvN7ITY0cgEoV0jKxKiNEeNbLfbppXLFi8Axtz9GQAzuxe4HHiqYh4H3mnlY/H5wKvAW7GjkQlCu0ZWJERpjhpZa1yaOFpJ6IuAFype7wV+s2qevwIeBF4E3gn8J/eqYxDAzG4EbgR473vfGytQEZHQjJ8vy5/WTWn+fKi41WKpeJj83blY58ta6UOvtYup7kT9HWA78B7gfOCvzOy4KNx9vbvn3D23cOHCloMUEQnR+PmyRvfNjXO+rJUW+l7gjIrXiym3xCt9Fviql88sjJnZs8C/Bn7UciQiIjNUWt2rrbTQnwDONrOzohOdV1PuXqn0PHARgJm9CzgHeKblKEREpG1NW+ju/paZ3QQ8DHQB97j7bjNbGU3PA2uBvzWzJyl30dzi7vpJYxuyME6FHK/y/zL+vJ2bRSetQ8pqrUuYueuzpevQ3f077v5+d3+fuw9E7+WjZI67v+jun3T3f+vuS939G5MZ9HSS5JdfaYx1kaahoSGWLl1KV1cXS5cuZWhoaMqWnTVpXJOv6/rTU294jZlKvxSdZO3+8qvThoaG6O/vZ926dRw+fJh169bR398/o5O6SFYpoU+irAzY046BgQEGBwdZvnw5c+bMYfny5QwODjIwMNDp0ESkinXq8CSXy/nIyEhHlh1HojGno/GR157WzQPz51OcZcwpOVe8/jq3vRKNtLj6tcmPI4XyXV1dHD58mDlz5hx7r1gsMm/ePI4ePTplcdQ7pxCnriyNcZ+GNMZDD6mOdiWJoZVzXY26R1tZZvU8ZrbV3XO15lULfRLYmoMUvjzGpu4Fx64tLc4yNnYvYP8tP5tW9yrs7e1leHh4wnvDw8P09vZOaRxp9JWqr1XSlqVzXaCEPmnSGrCn0/r7++nr62Pz5s0Ui0U2b95MX18f/f39nQ5NRKroFnSTJJSBtVasWAHAqlWrGB0dpbe3l4GBgWPvi0h70rxEOcg+9DT7SpP2qzUqMxl1Tnb5tGQljuksK+cTOv09S0vWPkcL+aNuH3qQLfTxlaHkISFKY5vOSh1ZEMrnAPWhi4gEQwldRCQQSuhVenp6JtxXECbed7Cnp6fDEU5Pui+pyOQLsg+9HQcOHGh6QlPiC6mfUiSr1EIXEQmEErqISCDU5TJJGnXNTOVY5hp7W7JM22e61EKfBFka30Hjl0iWtbt9aqz+idRCF5FpaXys/sHBQZYtW8bw8DB9fX0AM3ZoCrXQRWRa0lj9xwtyLJdxoYzDklYdIiFJe6z+NHR6LBe10EVkWurt7eWqq65i3rx5mBnz5s3jqquumvKx+rNECV1EpqVFixaxceNGrr/+en75y19y/fXXs3HjRhYtWtTp0DpGCb2BwqEC1z103bS8F6hI6B577DGuueYatmzZQk9PD1u2bOGaa67hscce63RoHaOE3kB+Z55tL2+bdncZEpkJjhw5wvr169m1axdHjx5l165drF+/niNHjnQ6tI5RQq+jcKjAprFNOM7GsY1qpYtkzNy5c8nnJza28vk8c+fO7VBEnafr0Kv47SfD6lPIn9ZNaf58mGWUiofJ353jtlcOlKeLSMfdcMMN3HLLLQCsXLmSfD7PLbfcwsqVKzscWefossUaZfa9sY9L77+UI0ffPnSb2zWXh658iIUnLdRliyIZsWrVKr7+9a9z5MgR5s6dyw033MC6des6Fk+nL1tUC72G/M48JS9NeK/kpSnvS68eD0ZjXYhMtG7duo4m8KxRQq9hx74dFEvFCe8VS0W279s+pXEocYtIHEroNWy4bEPdaYZucCEi2aSrXEREAqGELiISiJYSupldYmZ7zGzMzG6tMf1mM9sePXaZ2VEz092URSTzQhpTvWkfupl1AXcBFwN7gSfM7EF3f2p8Hnf/GvC1aP7fBb7o7lN3FwcRkQRCG1O9lRb6BcCYuz/j7m8C9wKXN5h/BdCRXVxPTw9mduwBTHjd06ODBhF5W2hjqreS0BcBL1S83hu9dxwzOwm4BLivzvQbzWzEzEYKhULcWJs6cOBAzVtajT8OHDiQ+jIbqbVjEZHsGB0dZdmyZRPeW7ZsGaOjo7Hqycp3vZWEXiuyehdI/y7wf+t1t7j7enfPuXtu4cKFrcY4bel+niLZ1tvby/Dw8IT3hoeHY4+pnpXveisJfS9wRsXrxcCLdea9mg51t4iIxNXf309fXx+bN2+mWCyyefNm+vr66O/v73RoibTyw6IngLPN7Czg55ST9u9Xz2RmpwAfA/4g1QhFRCbJ+InPVatWMTo6Sm9vLwMDA9PyhCi0kNDd/S0zuwl4GOgC7nH33Wa2Mpo+PsDJZ4BH3P2NSYt2ijTq/+ru7p7CSERksq1YsSITCbwy7yQdtymo0RazeoNnEZG06CbRIiIzgBK6iEggMjfaYr3+a3V7iIg0lrmEXpm41X8tItI6dbmIiARCCV1EJBBK6CIigQg2oRcOFbjuoevY/6v9nQ5FRGRKBJvQ8zvzbHt5G/kd+eYzi4gEIMiEXjhUYNPYJhxn49hGtdJFZEYIMqHnd+YpeQmAkpfUSheRGSG4hD7eOi+WigAUS0W10kVkRggqofvtJ5Mf/BCl4uEJ75eKh8nfncNvP7lDkYmITL6gErqtOciOM3MUZ00cPqA4y9h+Zg5bc7BDkYmITL7M/fS/XRsu21B3mtW8m56ISBiCaqGLiMxkSugiIoFQQhcRCURwfehpSeP+fiIiU0kJvQ4lbxGZbtTlIiISCCV0EZFAKKGLiARCCV1EJBBK6CIigVBCFxEJRHCXLVZeP16tu7t7CiMREZlaQSX06mvHzUzXk4vIjKEuFxGRQCihi4gEQgldRCQQLSV0M7vEzPaY2ZiZ3Vpnno+b2XYz221mj6UbpoiINNP0pKiZdQF3ARcDe4EnzOxBd3+qYp5Tgb8GLnH3583s9EmKV0RE6milhX4BMObuz7j7m8C9wOVV8/w+cL+7Pw/g7vvSDVNERJppJaEvAl6oeL03eq/S+4FuM/u+mW01sz+sVZGZ3WhmI2Y2UigUJkzr6enBzCY8ojLHHj09Pa1+LhGRGaeV69Br/VKn+uLu2cAHgYuAE4EfmNnj7v6TCYXc1wPrAXK53IQ6Dhw40PSa8UY/GhIRmelaSeh7gTMqXi8GXqwxz353fwN4w8y2AOcBP0FERKZEK10uTwBnm9lZZnYCcDXwYNU8m4CPmtlsMzsJ+E1gNN1QRUSkkaYtdHd/y8xuAh4GuoB73H23ma2MpufdfdTMHgJ2AiXgbnffNZmBi4jIRNapsU5yuZyPjIy8HUgL467EHZtFY7mISGjMbKu752pN0y9FRUQCoYQuIhIIJXQRkUAooYuIBCIzN7jw20+G1ac0n0dERGrKTEK3NQcnXJFSOFTg5i03c8fH7mDBiQvK85jhqzsUoIhIxmW2yyW/M8+2l7eR35HvdCgiItNCJhN64VCBTWObcJyNYxvZ/6v9nQ5JRCTzMpnQ8zvzlLwEQMlLaqWLiLQgcwl9vHVeLBUBKJaKaqWLiLQgcwm9snU+Tq10EZHmMpfQd+zbcax1Pq5YKrJ93/bOBCQiMk1k5rLFcRsu21B3mtW814aIiEAGW+giIpKMErqISCCU0EVEAqGELiISCCV0EZFAKKGLiAQic5ctpsHMjnuue4uKSOiCTOhK3iIyE6nLRUQkEJlqoVd2ldTS3d09RZGIiEw/mUnotbpJzEzdJyIiLVKXi4hIIJTQRUQCoYQuIhIIJXQRkUAooYuIBEIJXUQkEEroIiKBUEIXEQlESwndzC4xsz1mNmZmt9aY/nEze83MtkePr6QfqoiINNL0l6Jm1gXcBVwM7AWeMLMH3f2pqln/2d0/PQkxiohIC1ppoV8AjLn7M+7+JnAvcPnkhiUiInG1ktAXAS9UvN4bvVftI2a2w8y+a2b/plZFZnajmY2Y2UihUEgQroiI1NNKQq81BGL1iFnbgDPd/TxgHbCxVkXuvt7dc+6eW7hwYaxARUSksVYS+l7gjIrXi4EXK2dw94Pu/nr0/DvAHDNbkFqUIiLSVCsJ/QngbDM7y8xOAK4GHqycwcx+zaLBzM3sgqjeV9IOVkRE6mt6lYu7v2VmNwEPA13APe6+28xWRtPzwH8EPmdmbwG/Aq52DWQuIjKlrFN5N5fL+cjISMN5dIMLEZGJzGyru+dqTdMvRUVEAqGELiISCCV0EZFAKKGLiARCCV1EJBBK6CIigVBCFxEJhBK6iEgglNBFRAKhhC4iEggldBGRQCihi4gEQgldRCQQSugiIoFoOh76VIvuk3Hcaw2jKyLSWOYSuhK3iEgy6nIREQmEErqISCCU0EVEAqGELiISCCV0EZFAKKGLiARCCV1EJBBK6CIigbBO/ZDHzArAvzSZbQGwv43FtFs+pDqyEEMadWQhhqzUkYUYslJHFmKYqjrOdPeFNae4e2YfwEgny4dURxZi0OfQutC6mNw61OUiIhIIJXQRkUBkPaGv73D5kOrIQgxp1JGFGLJSRxZiyEodWYih43V07KSoiIikK+stdBERaZESuohIIDKZ0M3sHjPbZ2a7EpY/w8w2m9mome02s88nqGOemf3IzHZEdaxJGEuXmf3YzP4pYfnnzOxJM9tuZiMJ6zjVzDaY2dPROvlIzPLnRMsffxw0sy/ErOOL0XrcZWZDZjYv1oco1/H5qPzuVpdfa1sysx4ze9TMfhr97U5Qx+9FcZTMLJeg/Nei/8dOM3vAzE5NUMfaqPx2M3vEzN4Tt46KaX9qZm5mCxLEsdrMfl6xfXwqbgxmtsrM9kTr9C8TxPCPFct/zsy2J6jjfDN7fPy7ZmYXJKjjPDP7QfSd/baZndygfM08FXf7nKDdayYn4wFcCHwA2JWw/LuBD0TP3wn8BDg3Zh0GzI+ezwF+CHw4QSxfAv4B+KeEn+U5YEGb6/N/AX8UPT8BOLWNurqAX1D+cUOrZRYBzwInRq+/CVwXc7lLgV3ASZTvtPW/gbOTbEvAXwK3Rs9vBf4iQR29wDnA94FcgvKfBGZHz/8iYQwnVzz/z0A+bh3R+2cAD1P+oV/Dba1OHKuBP23x/1ir/PLo/zk3en16ks9RMf1O4CsJ4ngEuDR6/ing+wnqeAL4WPT8emBtg/I181Tc7bPykckWurtvAV5to/xL7r4tev7/gFHKSSVOHe7ur0cv50SPWGeQzWwx8O+Bu+OUS1PUQrgQGARw9zfd/ZdtVHkR8DN3b/Yr32qzgRPNbDblpPxizPK9wOPufsjd3wIeAz7TrFCdbelyyjs5or//IW4d7j7q7ntaCbxO+UeizwHwOLA4QR0HK16+gybbZ4Pv1X8DvtysfJM6WlKn/OeAr7r7kWiefUljMDMDrgKGEtThwHiL+hSabKN16jgH2BI9fxS4skH5enkq1vZZKZMJPU1mtgT4Dcot7Lhlu6JDt33Ao+4et47/TvmLUoq77AoOPGJmW83sxgTl/xVQAP5n1PVzt5m9o414rqbJl6Wau/8cuAN4HngJeM3dH4m53F3AhWZ2mpmdRLkFdUbMOsa9y91fimJ7CTg9YT1puR74bpKCZjZgZi8A1wBfSVD+MuDn7r4jyfIr3BR1/9wTq4ug7P3AR83sh2b2mJl9qI04Pgq87O4/TVD2C8DXovV5B/BnCerYBVwWPf89WtxGq/JU4u0z6IRuZvOB+4AvVLVmWuLuR939fMqtpwvMbGmMZX8a2OfuW+Mut8pvufsHgEuBPzazC2OWn035sPBv3P03gDcoH8bFZmYnUN5YvxWzXDflVsdZwHuAd5jZH8Spw91HKXdNPAo8BOwA3mpYaBows37Kn+Pvk5R39353PyMqf1PMZZ8E9JNgR1Dlb4D3AedT3mHfGbP8bKAb+DBwM/DNqKWdxApiNjgqfA74YrQ+v0h0VBvT9ZS/p1spd6O82axAu3mqUrAJ3czmUF5Jf+/u97dTV9RF8X3gkhjFfgu4zMyeA+4FPmFm30iw7Bejv/uAB4CGJ2pq2AvsrTi62EA5wSdxKbDN3V+OWe63gWfdveDuReB+4N/FXbi7D7r7B9z9QsqHuklaYQAvm9m7AaK/DQ/xJ4uZXQt8GrjGow7TNvwDDQ7v63gf5Z3sjmg7XQxsM7Nfi1OJu78cNX5KwNdJto3eH3Vz/ojyEW3Dk7O1RN15VwD/GLds5FrK2yaUGy1xPwfu/rS7f9LdP0h5x/KzRvPXyVOJt88gE3q0dx8ERt39vyasY+H4lQdmdiLlpPR0q+Xd/c/cfbG7L6HcTfF/3D1Wq9TM3mFm7xx/TvlEWqwrf9z9F8ALZnZO9NZFwFNx6qiQtPXzPPBhMzsp+t9cRLm/MBYzOz36+17KX9ykLbEHKX95if5uSlhPYmZ2CXALcJm7H0pYx9kVLy8jxvYJ4O5Puvvp7r4k2k73Uj5J94uYcby74uVniLmNAhuBT0R1vZ/yifskIxb+NvC0u+9NUBbKfeYfi55/ggQNhoptdBZwG5BvMG+9PJV8+2z17OlUPih/UV8CipQ3sr6Y5ZdR7nveCWyPHp+KWcevAz+O6thFk7PmTer6OAmucqHc/70jeuwG+hMu/3xgJPosG4HuBHWcBLwCnJIwhjWUE84u4O+IrmiIWcc/U94Z7QAuSrotAacB36P8hf0e0JOgjs9Ez48ALwMPxyw/BrxQsX02u0KlVh33RetzJ/BtYFHcOqqmP0fzq1xqxfF3wJNRHA8C745Z/gTgG9Fn2QZ8IsnnAP4WWNnGdrEM2BptXz8EPpigjs9TvlrlJ8BXiX6NX6d8zTwVd/usfOin/yIigQiyy0VEZCZSQhcRCYQSuohIIJTQRUQCoYQuIhIIJXQRkUAooYuIBOL/A3sOjyzoWm/LAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section33\"></a> \n",
    "## <font color=\"#004D7F\"> 3.3. Algoritmo alternativo</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pueden utilizar otros algoritmos para construir Random Subspace y deben configurarse para que tengan una varianza modestamente alta. \n",
    "- Un ejemplo es el algoritmo KNN donde el valor _k_ se puede establecer en un valor bajo.\n",
    "- El algoritmo utilizado en el conjunto se especifica mediante el argumento `estimator` y debe establecerse en una instancia del algoritmo y la configuración del algoritmo que se utilizará. \n",
    "- El siguiente ejemplo demuestra el uso de `KNeighborsClassifier` como algoritmo base utilizado en el conjunto Random Subspace a través de la clase `Bagging`. \n",
    "- Aquí, el algoritmo se utiliza con hiperparámetros predeterminados donde _k_ se establece en 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Más información sobre la clase [`KNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn-neighbors-kneighborsclassifier)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy medio: 0.905 (0.035)\n"
     ]
    }
   ],
   "source": [
    "# evaluate random subspace ensemble with knn algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "X, y = get_dataset()\n",
    "# definir el modelo\n",
    "model = BaggingClassifier(base_estimator=KNeighborsClassifier(), bootstrap=False, max_features=10, n_jobs=-1)\n",
    "# definir el procedimiento de evaluación\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluar el modelo\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# resumir la precisión\n",
    "print('Accuracy medio: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sectionEj\"></a>\n",
    "<h3><font color=\"#004D7F\" size=6> <i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\" style=\"color:#113D68\"></i> Ejercicios</font></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se proponen las siguientes actividades para consolidar el aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 1</font>\n",
    "__Hiperparámtros__. Explore diferentes configuraciones para la cantidad de árboles e incluso configuraciones de árbol individuales para ver si puede mejorar aún más los resultados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparámetros de BaggingClassifier\n",
    "\n",
    "El `BaggingClassifier` es un meta-estimador de ensamblado que ajusta clasificadores base en subconjuntos aleatorios del conjunto de datos original y luego agrega sus predicciones individuales (ya sea por votación o promediando) para formar una predicción final.\n",
    "\n",
    "#### Parámetros\n",
    "\n",
    "- **estimator**: objeto, por defecto `None`\n",
    "  - El estimador base para ajustar en subconjuntos aleatorios del conjunto de datos. Si es `None`, el estimador base es un `DecisionTreeClassifier`.\n",
    "\n",
    "- **n_estimators**: int, por defecto `10`\n",
    "  - El número de estimadores base en el ensamblado.\n",
    "\n",
    "- **max_samples**: int o float, por defecto `1.0`\n",
    "  - El número de muestras a extraer de `X` para entrenar cada estimador base (con reemplazo por defecto, ver `bootstrap` para más detalles). Si es int, extrae `max_samples` muestras. Si es float, extrae `max_samples * X.shape[0]` muestras.\n",
    "\n",
    "- **max_features**: int o float, por defecto `1.0`\n",
    "  - El número de características a extraer de `X` para entrenar cada estimador base (sin reemplazo por defecto, ver `bootstrap_features` para más detalles). Si es int, extrae `max_features` características. Si es float, extrae `max(1, int(max_features * n_features_in_))` características.\n",
    "\n",
    "- **bootstrap**: bool, por defecto `True`\n",
    "  - Si las muestras se extraen con reemplazo. Si es `False`, se realiza el muestreo sin reemplazo.\n",
    "\n",
    "- **bootstrap_features**: bool, por defecto `False`\n",
    "  - Si las características se extraen con reemplazo.\n",
    "\n",
    "- **oob_score**: bool, por defecto `False`\n",
    "  - Si se utilizan muestras fuera de bolsa para estimar el error de generalización. Solo disponible si `bootstrap=True`.\n",
    "\n",
    "- **warm_start**: bool, por defecto `False`\n",
    "  - Si se reutiliza la solución de la llamada anterior a `fit` y se añaden más estimadores al ensamblado, de lo contrario, simplemente se ajusta un nuevo ensamblado.\n",
    "\n",
    "- **n_jobs**: int, por defecto `None`\n",
    "  - El número de trabajos a ejecutar en paralelo tanto para `fit` como para `predict`. `None` significa 1 a menos que esté en un contexto `joblib.parallel_backend`. `-1` significa usar todos los procesadores.\n",
    "\n",
    "- **random_state**: int, RandomState instance o None, por defecto `None`\n",
    "  - Controla la aleatoriedad de las muestras extraídas y el estimador base. Pase un int para una salida reproducible en múltiples llamadas a funciones.\n",
    "\n",
    "- **verbose**: int, por defecto `0`\n",
    "  - Controla el nivel de verbosidad de la salida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 2</font>\n",
    "__Bag de otro algoritmo__. Se pueden utilizar otros algoritmos con Random Subspace. Por ejemplo, un algoritmo diferente de _k_-nearest neighbor. Busque alguno que sea adecuado paa este tipo de problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmos que Funcionan Bien con BaggingClassifier\n",
    "\n",
    "El `BaggingClassifier` es un meta-estimador que puede mejorar la precisión y reducir la varianza de varios clasificadores base. Aquí tienes algunos algoritmos que suelen funcionar bien cuando se utilizan con `BaggingClassifier`:\n",
    "\n",
    "#### 1. Árboles de Decisión\n",
    "Los `DecisionTreeClassifier` son comúnmente utilizados como estimadores base en bagging debido a su alta varianza. El bagging ayuda a reducir esta varianza y mejora la estabilidad del modelo.\n",
    "\n",
    "#### 2. Regresión Logística\n",
    "Aunque la `LogisticRegression` no es tan común en bagging como los árboles de decisión, puede beneficiarse de la reducción de varianza que ofrece el bagging.\n",
    "\n",
    "#### 3. K-Nearest Neighbors (KNN)\n",
    "El `KNeighborsClassifier` puede beneficiarse del bagging, especialmente en conjuntos de datos con ruido, ya que el bagging puede ayudar a suavizar las predicciones.\n",
    "\n",
    "#### 4. Máquinas de Soporte Vectorial (SVM)\n",
    "Las `SVC` pueden beneficiarse del bagging, aunque no tanto como los árboles de decisión, ya que las SVM suelen tener una varianza más baja.\n",
    "\n",
    "#### 5. Naive Bayes\n",
    "El `GaussianNB` puede beneficiarse del bagging en ciertos casos, aunque su rendimiento puede no mejorar tanto como con otros clasificadores debido a su naturaleza probabilística.\n",
    "\n",
    "#### 6. Redes Neuronales\n",
    "Las redes neuronales pueden beneficiarse del bagging, aunque no es tan común debido a su complejidad y tiempo de entrenamiento.\n",
    "\n",
    "En general, los algoritmos con alta varianza tienden a beneficiarse más del bagging, ya que este método ayuda a reducir la varianza y mejorar la estabilidad del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 3</font>\n",
    "__Problema de Regresión__. Random Subspace se puede utilizar con árboles de regresión. En lugar de predecir el valor de clase más común del conjunto de predicciones, puede devolver el promedio de las predicciones de los árboles bagging. Experimente con problemas de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.27806269394470257\n",
      "Real: 0.477, Predicted: 0.6267999999999999\n",
      "Real: 0.458, Predicted: 0.7907\n",
      "Real: 5.00001, Predicted: 4.710303\n",
      "Real: 2.186, Predicted: 2.5318999999999994\n",
      "Real: 2.78, Predicted: 1.886\n",
      "Real: 1.587, Predicted: 1.7386000000000004\n",
      "Real: 1.982, Predicted: 2.4273999999999996\n",
      "Real: 1.575, Predicted: 1.8216\n",
      "Real: 3.4, Predicted: 2.920101\n",
      "Real: 4.466, Predicted: 4.523406\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Cargar el dataset\n",
    "data = fetch_california_housing()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Definir el BaggingRegressor con un DecisionTreeRegressor como estimador base\n",
    "bagging_regressor = BaggingRegressor(base_estimator=DecisionTreeRegressor(), bootstrap=False, max_features=5, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "bagging_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predecir\n",
    "y_pred = bagging_regressor.predict(X_test)\n",
    "\n",
    "# Calcular el error cuadrático medio\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Mostrar las primeras 10 predicciones comparadas con los valores reales\n",
    "for i in range(10):\n",
    "    print(f\"Real: {y_test[i]}, Predicted: {y_pred[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 4</font>\n",
    "__Datasets reales__. Busque un dataset original y verdadero (que no sea sintético) y evalúe el uso de los conceptos vistos en esta unidad. Los conjuntos de datos en pueden ser obtenidos del [repositorio de aprendizaje automático de UCI](https://archive.ics.uci.edu/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.27806269394470257\n",
      "Real: 0.477, Predicted: 0.6267999999999999\n",
      "Real: 0.458, Predicted: 0.7907\n",
      "Real: 5.00001, Predicted: 4.710303\n",
      "Real: 2.186, Predicted: 2.5318999999999994\n",
      "Real: 2.78, Predicted: 1.886\n",
      "Real: 1.587, Predicted: 1.7386000000000004\n",
      "Real: 1.982, Predicted: 2.4273999999999996\n",
      "Real: 1.575, Predicted: 1.8216\n",
      "Real: 3.4, Predicted: 2.920101\n",
      "Real: 4.466, Predicted: 4.523406\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Cargar el dataset\n",
    "data = fetch_california_housing()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Definir el BaggingRegressor con un DecisionTreeRegressor como estimador base\n",
    "bagging_regressor = BaggingRegressor(base_estimator=DecisionTreeRegressor(), bootstrap=False, max_features=5, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "bagging_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predecir\n",
    "y_pred = bagging_regressor.predict(X_test)\n",
    "\n",
    "# Calcular el error cuadrático medio\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Mostrar las primeras 10 predicciones comparadas con los valores reales\n",
    "for i in range(10):\n",
    "    print(f\"Real: {y_test[i]}, Predicted: {y_pred[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 5</font>\n",
    "__Valores de _k___. Juegue con diferentes valores de _k_ cuando se utiliza KNN en Random Subspace y analice la salida dada. Vea los ejemplos vistos en Random Subspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 6</font>\n",
    "__Extensiones__. En la unidad anterior vimos extensiones como Pasting y Random Patches. Evalúe si estas extensiones aplican a Random Subspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 7</font>\n",
    "__Búsqueda de la mejor configuración__. Como se ha visto existen diferentes hiperparámetros que pueden ajustar nuestro modelo. Haga una búsqueda para un dataset real de cuales, entre un rango amplio de hiperparétros, maximizan la métrica. Puede utilizar una búsqueda aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
