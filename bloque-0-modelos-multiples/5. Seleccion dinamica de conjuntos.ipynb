{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"#004D7F\" size=5>Módulo 1: Modelos múltiples</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#004D7F\" size=6> 5. Seleccion dinamica de conjuntos </font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Manuel Castillo-Cara</font><br>\n",
    "<font color=\"#004D7F\" size=3>Aprendizaje Automático II</font><br>\n",
    "<font color=\"#004D7F\" size=3>Universidad Nacional de Educación a Distancia</font>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "\n",
    "\n",
    "* [1. Selección dinámica de conjuntos](#section1)\n",
    "   * [1.1. Librería DESlib](#section11)\n",
    "   * [1.2. Dataset](#section12)\n",
    "* [2. Evaluación de modelos KNORA](#section2)\n",
    "    * [2.1. KNORA-Eliminate (KNORA-E)](#section21)\n",
    "    * [2.2. KNORA-Union (KNORA-U)](#section22)\n",
    "* [3. Ajuste de hiperparámetros para KNORA](#section3)\n",
    "    * [3.1. Parámetro `k` en KNN](#section31)\n",
    "    * [3.2. Explorar algoritmos para el grupo de clasificadores](#section32)\n",
    "* [Ejercicios](#sectionEj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section0\"></a>\n",
    "# <font color=\"#004D7F\">0. Contexto</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Es una técnica de aprendizaje de conjuntos que selecciona automáticamente un subconjunto de miembros del conjunto justo a tiempo al realizar una predicción. \n",
    "- Implica ajustar múltiples modelos en train y luego seleccionar los modelos que se espera que funcionen mejor al hacer una predicción.\n",
    "- Se suele usar un modelo KNN para ubicar ejemplos que estén más cerca del nuevo ejemplo que se va a predecir, evaluando todos en el vecindario y usando los modelos que funcionan mejor en el vecindario para hacer una predicción para el nuevo ejemplo. \n",
    "\n",
    "En este tutorial veremos:\n",
    "- Cómo son los algoritmos de selección dinámica.\n",
    "- Cómo desarrollar y evaluar la selección de conjuntos usando Scikit-learn.\n",
    "- Cómo explorar los hiperparámetros de selección dinámica de conjuntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\"> 1. Selección dinámica de conjuntos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de clasificador dinámico Vs. Selección dinámica de conjuntos\n",
    "\n",
    "- __Selección de clasificador dinámico (DCS)__: algoritmos que eligen dinámicamente __uno entre muchos__ modelos entrenados para hacer una predicción basada en los detalles específicos de la entrada.\n",
    "- __Selección dinámica de conjuntos (DES)__: algoritmos que eligen dinámicamente __un subconjunto__ de modelos entrenados para hacer una predicción basada en los detalles específicos de la entrada.\n",
    "\n",
    "Los algoritmos DES funcionan de manera muy similar a los algoritmos DCS, excepto que __las predicciones se realizan utilizando votos de múltiples modelos clasificadores__ en lugar de un único mejor modelo. De hecho, cada región del espacio de características de entrada pertenece a un subconjunto de modelos que funcionan mejor en esa región.\n",
    "\n",
    "\n",
    "### KNORA\n",
    "___k_-Nearest Neighbor Oracle (KNORA)__ es el enfoque más común, es una extensión natural del algoritmo de _Dynamic Classifier Selection Local Accuracy (DCS-LA)_. \n",
    "- DCS-LA implica seleccionar los _k_ vecinos más cercanos de train para un nuevo patrón de entrada determinado, luego seleccionar el mejor clasificador en función de su desempeño en esa vecindad de _k_ ejemplos para hacer una predicción sobre el nuevo ejemplo.\n",
    "- KNORA selecciona múltiples modelos que funcionan bien en la vecindad y cuyas predicciones luego se combinan mediante votación mayoritaria para hacer una predicción de resultado final.\n",
    "\n",
    "Los modelos de clasificador seleccionados se denominan ___oráculos___ (_oracles_). \n",
    "\n",
    "### Versiones KNORA\n",
    "\n",
    "Se describen dos versiones de KNORA:\n",
    "- __KNORA-Eliminate (KNORA-E)__: Conjunto de clasificadores que consigue un accuracy perfecto en la vecindad del nuevo ejemplo, reduciendo el tamaño de la vecindad hasta localizar al menos un clasificador perfecto.\n",
    "- __KNORA-Union (KNORA-U)__: Conjunto de todos los clasificadores que realizan al menos una predicción correcta sobre la vecindad con votación ponderada y votos proporcionales al accuracy de la vecindad.\n",
    "\n",
    "### KNORA-E\n",
    "- Implica seleccionar todos los clasificadores que logren predicciones perfectas sobre la vecindad de _k_ ejemplos en la vecindad. \n",
    "- Si ningún clasificador logra un accuracy del 100%, el tamaño del vecindario se reduce en uno y los modelos se reevalúan. \n",
    "- Este proceso se repite hasta que se descubre uno o más modelos que tienen un rendimiento perfecto y luego se utilizan para hacer una predicción para el nuevo ejemplo.\n",
    "\n",
    "\n",
    "### KNORA-U\n",
    "- Implica seleccionar todos los clasificadores que hagan al menos una predicción correcta en el vecindario. \n",
    "- Luego, las predicciones de cada clasificador se combinan utilizando un promedio ponderado, donde el número de predicciones correctas en el vecindario indica el número de votos asignados a cada clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section11\"></a>\n",
    "## <font color=\"#004D7F\"> 1.1. Librería DESlib</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio usaremos también DESlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install deslib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Más información sobre la librería [DESlib](https://deslib.readthedocs.io/en/latest/).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Más información sobre la librería [DESlib](https://deslib.readthedocs.io/en/latest/).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Más información sobre el Github [DESlib](https://github.com/scikit-learn-contrib/DESlib).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Más información en PyPI sobre [DESlib](https://pypi.org/project/DESlib/0.1/).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESlib proporciona una implementación del algoritmo KNORA a través de las clases `KNORAE` y `KNORAU`. \n",
    "- Ambas clases utilizan un algoritmo KNN para seleccionar el vecino con un valor predeterminado de `k = 7`. \n",
    "- Se utiliza un conjunto Bagging como conjunto de modelos de clasificador de forma predeterminada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section12\"></a>\n",
    "## <font color=\"#004D7F\"> 1.2. Dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar la función `make_classification()` para crear un problema de clasificación binaria sintética con 10,000 ejemplos y 20 características de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 20) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=10000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ejecución del ejemplo crea el conjunto de datos y resume la forma de la entrada y la salida de elementos del conjunto de datos para modelar, confirmando la configuración elegida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: La libreía no ha sido actualizada a la última versión de Numpy, es por eso que le salen muchos errores tipo warning. Por tanto, tenga en cuenta que le van a salir muchos fallos, no se preocupue, ejecute primero con la versión que tenga y verifique que (aunque se salgan muchos errores tipo warning) obtenga un resultado.  Sin le sale un resultado con `nan` entonces tiene que realizar una instalación a una versión posterior. También le aparecerán varios errores tipo warning seguramente, omítalos y verifique que le salga un accuracy casi al final.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.22.0 Requires-Python >=3.8; 1.22.1 Requires-Python >=3.8; 1.22.2 Requires-Python >=3.8; 1.22.3 Requires-Python >=3.8; 1.22.4 Requires-Python >=3.8; 1.23.0 Requires-Python >=3.8; 1.23.1 Requires-Python >=3.8; 1.23.2 Requires-Python >=3.8; 1.23.3 Requires-Python >=3.8; 1.23.4 Requires-Python >=3.8; 1.23.5 Requires-Python >=3.8; 1.24.0 Requires-Python >=3.8; 1.24.1 Requires-Python >=3.8; 1.24.2 Requires-Python >=3.8; 1.24.3 Requires-Python >=3.8; 1.24.4 Requires-Python >=3.8; 1.25.0 Requires-Python >=3.9; 1.25.1 Requires-Python >=3.9; 1.25.2 Requires-Python >=3.9; 1.26.0 Requires-Python <3.13,>=3.9; 1.26.1 Requires-Python <3.13,>=3.9; 1.26.2 Requires-Python >=3.9; 1.26.3 Requires-Python >=3.9; 1.26.4 Requires-Python >=3.9; 2.0.0 Requires-Python >=3.9; 2.0.1 Requires-Python >=3.9; 2.0.2 Requires-Python >=3.9; 2.1.0 Requires-Python >=3.10; 2.1.0rc1 Requires-Python >=3.10; 2.1.1 Requires-Python >=3.10; 2.1.2 Requires-Python >=3.10; 2.1.3 Requires-Python >=3.10; 2.2.0 Requires-Python >=3.10; 2.2.0rc1 Requires-Python >=3.10; 2.2.1 Requires-Python >=3.10; 2.2.2 Requires-Python >=3.10; 2.2.3 Requires-Python >=3.10\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement numpy==1.23.5 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for numpy==1.23.5\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install \"numpy==1.23.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19.1\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(numpy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a> \n",
    "# <font color=\"#004D7F\"> 2. Evaluación de modelos KNORA </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que estamos familiarizados con la API DESlib, veamos cómo utilizar cada algoritmo KNORA-E y KNORA-U."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section21\"></a> \n",
    "## <font color=\"#004D7F\"> 2.1. KNORA-Eliminate (KNORA-E)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos evaluar un modelo KNORA-E en el conjunto de datos sintéticos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section211\"></a> \n",
    "### <font color=\"#004D7F\"> 2.1.1. Evaluación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la evaluación:\n",
    "- En este caso, usaremos hiperparámetros del modelo predeterminado, con Bagging y `k = 7` para la selección de la vecindad local. \n",
    "- Utilizamos una validación cruzada estratificada repetida de _k_ veces con 3 repeticiones y 10 pliegues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy medio: 0.915 (0.009)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from deslib.des.knora_e import KNORAE\n",
    "\n",
    "# definir el modelo\n",
    "model = KNORAE()\n",
    "# Validación cruzada\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# Evaluación\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy medio: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section22\"></a> \n",
    "## <font color=\"#004D7F\"> 2. KNORA-Union (KNORA-U)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos evaluar un modelo KNORA-U en el conjunto de datos sintéticos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section221\"></a> \n",
    "### <font color=\"#004D7F\"> 2.2.1. Evaluación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la evaluación:\n",
    "- En este caso, usaremos hiperparámetros del modelo predeterminado, incluidos bagging como conjunto de modelos clasificadores y `k = 7` para la selección de la vecindad local al hacer una predicción. \n",
    "- Evaluaremos el modelo utilizando una validación cruzada estratificada repetida de _k_ veces con 3 repeticiones y 10 pliegues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy medio: 0.935 (0.008)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from deslib.des.knora_u import KNORAU\n",
    "\n",
    "# definir el modelo\n",
    "model = KNORAU()\n",
    "# Validación cruzada\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# Evaluación\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy medio: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a> \n",
    "# <font color=\"#004D7F\"> 3. Ajuste de hiperparámetros para KNORA</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay muchos hiperparámetros que podemos observar para KNORA, aunque en este caso, veremos el valor de `k` en el modelo KNN utilizado en la evaluación local de los modelos, y cómo usar un hiperparámetro personalizados para el conjunto de clasificadores. \n",
    "\n",
    "Usaremos KNORA-U como base para estos experimentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section31\"></a> \n",
    "## <font color=\"#004D7F\"> 3.1. Parámetro `k` en KNN</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La configuración del algoritmo de KNN es fundamental ya que define la vecindad en la que se considera cada clasificador. El valor `k` controla el tamaño de la vecindad:\n",
    "- Valores demasiado pequeños significará que los ejemplos relevantes en el conjunto de entrenamiento podrían excluirse de la vecindad.\n",
    "- Valores demasiado grandes pueden significar que la señal está siendo eliminada por demasiados ejemplos. \n",
    "\n",
    "Veamos con valores `k` de 2 a 21."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from deslib.des.knora_u import KNORAU\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=10000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de modelos\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    # exploramos valores de k de 2 a 21\n",
    "    for n in range(2, 22):\n",
    "        models[str(n)] = KNORAU(k=n)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluación de cada modelo\n",
    "def evaluate_model(model, X, y):\n",
    "    # Validación cruzada\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # Evaluación\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">2 0.934 (0.008)\n",
      ">3 0.933 (0.007)\n",
      ">4 0.935 (0.009)\n",
      ">5 0.933 (0.010)\n",
      ">6 0.937 (0.008)\n",
      ">7 0.935 (0.007)\n",
      ">8 0.937 (0.011)\n",
      ">9 0.935 (0.009)\n",
      ">10 0.937 (0.009)\n",
      ">11 0.936 (0.006)\n",
      ">12 0.933 (0.009)\n",
      ">13 0.935 (0.009)\n",
      ">14 0.936 (0.009)\n",
      ">15 0.936 (0.010)\n",
      ">16 0.935 (0.007)\n",
      ">17 0.935 (0.008)\n",
      ">18 0.934 (0.010)\n",
      ">19 0.936 (0.009)\n",
      ">20 0.939 (0.007)\n",
      ">21 0.933 (0.007)\n"
     ]
    }
   ],
   "source": [
    "# definir el dataset\n",
    "X, y = get_dataset()\n",
    "# obtener los modelos\n",
    "models = get_models()\n",
    "# evaluación y almacenamiento de resultados\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section32\"></a> \n",
    "## <font color=\"#004D7F\"> 3.2. Explorar algoritmos para el grupo de clasificadores</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto de forma predeterminada utiliza Bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section321\"></a> \n",
    "### <font color=\"#004D7F\"> 3.2.1. Grupo de clasificadores</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede considerar un grupo personalizado de clasificadores. Esto requiere:\n",
    "1. Primero definir una lista de modelos de clasificador para usar y ajustar cada uno en el conjunto de datos de entrenamiento. \n",
    "    - Desafortunadamente, esto significa que los métodos automáticos de evaluación del modelo de validación cruzada k-fold en scikit-learn no se pueden utilizar en este caso. \n",
    "2. En su lugar, utilizaremos una división de prueba de entrenamiento para poder ajustar el grupo de clasificadores manualmente en el conjunto de datos de entrenamiento.\n",
    "    - La lista de clasificadores aptos se puede especificar para la clase KNORA-U (o KNORA-E) a través del argumento `pool_classifiers`. En este caso, utilizaremos un grupo que incluye regresión logística, un árbol de decisión y Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from deslib.des.knora_u import KNORAU\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X, y = get_dataset()\n",
    "# división en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "# pool de clasificadores\n",
    "classifiers = [LogisticRegression(), DecisionTreeClassifier(), GaussianNB()]\n",
    "# entrenamos en train cada clasificador\n",
    "for c in classifiers:\n",
    "    c.fit(X_train, y_train)\n",
    "# definimos el modelo KNORA-U con los clasificadores entrenados\n",
    "model = KNORAU(pool_classifiers=classifiers)\n",
    "# Entrenamos KNORA\n",
    "model.fit(X_train, y_train)\n",
    "# Hacer prediciones en test y evaluar\n",
    "pred = model.predict(X_test)\n",
    "score = accuracy_score(y_test, pred)\n",
    "print('Accuracy: %.3f' % (score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section322\"></a> \n",
    "### <font color=\"#004D7F\"> 3.2.2. Modelo contribuyente</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para adoptar el modelo KNORA, debe funcionar mejor que cualquier modelo contribuyente. De lo contrario, simplemente utilizaríamos el modelo contribuyente que funcione mejor. Podemos verificar esto evaluando el desempeño de cada clasificador contribuyente en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 0.873\n",
      ">LogisticRegression: 0.878\n",
      ">DecisionTreeClassifier: 0.881\n",
      ">GaussianNB: 0.873\n"
     ]
    }
   ],
   "source": [
    "# evaluate contributing models\n",
    "print('Total accuracy: %.3f' % (score))\n",
    "for c in classifiers:\n",
    "    pred = c.predict(X_test)\n",
    "    score = accuracy_score(y_test, pred)\n",
    "    print('>%s: %.3f' % (c.__class__.__name__, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ejecución del ejemplo primero informa el accuracy medio del modelo con el grupo personalizado de clasificadores y el accuracy de cada modelo contribuyente.\n",
    "\n",
    "En este caso, podemos ver que nuevamente, el KNORA-U logra un accuracy de alrededor del 91,3%, que es mejor que cualquier modelo contribuyente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section323\"></a> \n",
    "### <font color=\"#004D7F\"> 3.2.3. Modelo contribuyente único</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lugar de especificar un conjunto de clasificadores, también es posible especificar un algoritmo de conjunto único de la biblioteca scikit-learn y el algoritmo KNORA utilizará automáticamente los miembros internos del conjunto como clasificadores. \n",
    "\n",
    "Por ejemplo, podemos utilizar Random Forest con 1000 miembros como clasificador base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from deslib.des.knora_u import KNORAU\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X, y = get_dataset()\n",
    "# division en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "# definimos el pool\n",
    "pool = RandomForestClassifier(n_estimators=1000)\n",
    "# entrenamos en trainfit the classifiers on the training set\n",
    "pool.fit(X_train, y_train)\n",
    "# definimos KNORAU\n",
    "model = KNORAU(pool_classifiers=pool)\n",
    "# entrenamos en train\n",
    "model.fit(X_train, y_train)\n",
    "# evaluamos\n",
    "pred = model.predict(X_test)\n",
    "score = accuracy_score(y_test, pred)\n",
    "print('Accuracy: %.3f' % (score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">RandomForestClassifier: 0.966\n"
     ]
    }
   ],
   "source": [
    "# evaluamos el modelo solo\n",
    "pred = pool.predict(X_test)\n",
    "score = accuracy_score(y_test, pred)\n",
    "print('>%s: %.3f' % (pool.__class__.__name__, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i> __Nota__: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y comparar el resultado promedio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sectionEj\"></a>\n",
    "<h3><font color=\"#004D7F\" size=6> <i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\" style=\"color:#113D68\"></i> Ejercicios</font></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se proponen las siguientes actividades para consolidar el aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 1</font>\n",
    "__KNORA-E__. En los ejemplos finales hemos visto para KNORA-U, utilice el ejemplo con KNORA-E."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.971\n",
      ">RandomForestClassifier: 0.967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from deslib.des.knora_e import KNORAE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X, y = get_dataset()\n",
    "# division en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "# definimos el pool\n",
    "pool = RandomForestClassifier(n_estimators=1000)\n",
    "# entrenamos en trainfit the classifiers on the training set\n",
    "pool.fit(X_train, y_train)\n",
    "# definimos KNORAE\n",
    "model = KNORAE(pool_classifiers=pool)\n",
    "# entrenamos en train\n",
    "model.fit(X_train, y_train)\n",
    "# evaluamos\n",
    "pred = model.predict(X_test)\n",
    "score = accuracy_score(y_test, pred)\n",
    "print('Accuracy: %.3f' % (score))\n",
    "\n",
    "# evaluamos el modelo solo\n",
    "pred = pool.predict(X_test)\n",
    "score = accuracy_score(y_test, pred)\n",
    "print('>%s: %.3f' % (pool.__class__.__name__, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 2</font>\n",
    "__Hiperparámetros__. ¿Qué otros hiperparámetros se pueden utilizar? Indaga y descubra más hiperparámetros y evalúe su uso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hiperparámetros de KNORAU y KNORAE\n",
    "\n",
    "## KNORAU (k-Nearest Oracles Union)\n",
    "\n",
    "1. **`pool_classifiers`**: Lista de clasificadores (por defecto = `None`). El conjunto de clasificadores entrenados para el problema de clasificación correspondiente.\n",
    "2. **`k`**: Número de vecinos utilizados para estimar la competencia de los clasificadores base (por defecto = `7`).\n",
    "3. **`DFP`**: Booleano que determina si se aplica la poda dinámica de frienemy (por defecto = `False`).\n",
    "4. **`with_IH`**: Booleano que indica si se utiliza el nivel de dureza de la región de competencia para decidir entre usar el algoritmo DS o el KNN (por defecto = `False`).\n",
    "5. **`safe_k`**: Tamaño de la región de indecisión (por defecto = `None`).\n",
    "6. **`IH_rate`**: Umbral de dureza. Si el nivel de dureza de la región de competencia es menor que `IH_rate`, se utiliza el clasificador KNN. De lo contrario, se utiliza el algoritmo DS (por defecto = `0.3`).\n",
    "7. **`random_state`**: Controla la aleatoriedad del clasificador (por defecto = `None`).\n",
    "8. **`knn_classifier`**: Algoritmo utilizado para estimar la región de competencia (`'knn'`, `'faiss'`, `None`; por defecto = `'knn'`).\n",
    "9. **`knn_metric`**: Métrica utilizada por el clasificador k-NN para estimar distancias (`'minkowski'`, `'cosine'`, `'mahalanobis'`; por defecto = `'minkowski'`).\n",
    "10. **`knne`**: Booleano que indica si se utiliza la igualdad de k-vecinos más cercanos (KNNE) para la estimación de la región de competencia (por defecto = `False`).\n",
    "11. **`DSEL_perc`**: Porcentaje de los datos de entrada utilizados para ajustar DSEL (por defecto = `0.5`).\n",
    "12. **`voting`**: Método de votación (`'hard'`, `'soft'`; por defecto = `'hard'`).\n",
    "\n",
    "## KNORAE (k-Nearest Oracles Eliminate)\n",
    "\n",
    "1. **`pool_classifiers`**: Lista de clasificadores (por defecto = `None`). El conjunto de clasificadores entrenados para el problema de clasificación correspondiente.\n",
    "2. **`k`**: Número de vecinos utilizados para estimar la competencia de los clasificadores base (por defecto = `7`).\n",
    "3. **`DFP`**: Booleano que determina si se aplica la poda dinámica de frienemy (por defecto = `False`).\n",
    "4. **`with_IH`**: Booleano que indica si se utiliza el nivel de dureza de la región de competencia para decidir entre usar el algoritmo DS o el KNN (por defecto = `False`).\n",
    "5. **`safe_k`**: Tamaño de la región de indecisión (por defecto = `None`).\n",
    "6. **`IH_rate`**: Umbral de dureza. Si el nivel de dureza de la región de competencia es menor que `IH_rate`, se utiliza el clasificador KNN. De lo contrario, se utiliza el algoritmo DS (por defecto = `0.3`).\n",
    "7. **`random_state`**: Controla la aleatoriedad del clasificador (por defecto = `None`).\n",
    "8. **`knn_classifier`**: Algoritmo utilizado para estimar la región de competencia (`'knn'`, `'faiss'`, `None`; por defecto = `'knn'`).\n",
    "9. **`knn_metric`**: Métrica utilizada por el clasificador k-NN para estimar distancias (`'minkowski'`, `'cosine'`, `'mahalanobis'`; por defecto = `'minkowski'`).\n",
    "10. **`knne`**: Booleano que indica si se utiliza la igualdad de k-vecinos más cercanos (KNNE) para la estimación de la región de competencia (por defecto = `False`).\n",
    "11. **`DSEL_perc`**: Porcentaje de los datos de entrada utilizados para ajustar DSEL (por defecto = `0.5`).\n",
    "12. **`voting`**: Método de votación (`'hard'`, `'soft'`; por defecto = `'hard'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 3</font>\n",
    "__Más conjuntos de datos__. Busque un dataset original y verdadero (que no sea sintético) y evalúe el uso de los conceptos vistos en esta unidad. Los conjuntos de datos en pueden ser obtenidos del [repositorio de aprendizaje automático de UCI](https://archive.ics.uci.edu/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNORAU Accuracy: 1.000\n",
      "KNORAE Accuracy: 1.000\n",
      "Accuracy total KNORAU: 1.000\n",
      "Accuracy total KNORAE: 1.000\n",
      ">SVC: 0.983\n",
      ">RandomForestClassifier: 1.000\n",
      ">KNeighborsClassifier: 0.966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from deslib.dcs.ola import OLA\n",
    "from deslib.des.knora_u import KNORAU\n",
    "from deslib.des.knora_e import KNORAE\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar el dataset\n",
    "data = load_wine()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Definir nuevos clasificadores\n",
    "classifiers = [SVC(), RandomForestClassifier(), KNeighborsClassifier()]\n",
    "\n",
    "# Entrenar cada clasificador en train\n",
    "for c in classifiers:\n",
    "    c.fit(X_train, y_train)\n",
    "\n",
    "# Aplicar KNORAU\n",
    "knorau = KNORAU(pool_classifiers=classifiers)\n",
    "knorau.fit(X_train, y_train)\n",
    "pred_knorau = knorau.predict(X_test)\n",
    "score_knorau = accuracy_score(y_test, pred_knorau)\n",
    "print('KNORAU Accuracy: %.3f' % (score_knorau))\n",
    "\n",
    "# Aplicar KNORAE\n",
    "knorae = KNORAE(pool_classifiers=classifiers)\n",
    "knorae.fit(X_train, y_train)\n",
    "pred_knorae = knorae.predict(X_test)\n",
    "score_knorae = accuracy_score(y_test, pred_knorae)\n",
    "print('KNORAE Accuracy: %.3f' % (score_knorae))\n",
    "\n",
    "# Evaluar los modelos contribuyentes\n",
    "print('Accuracy total KNORAU: %.3f' % (score_knorau))\n",
    "print('Accuracy total KNORAE: %.3f' % (score_knorae))\n",
    "for c in classifiers:\n",
    "    pred = c.predict(X_test)\n",
    "    score = accuracy_score(y_test, pred)\n",
    "    print('>%s: %.3f' % (c.__class__.__name__, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 4</font>\n",
    "__Clasificadores__. Evalué todo los ejercicios anteriores con el uso de clasificadores distintos a los vistos en la unidad, i.e., diferentes a LoR, CART y NB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNORAU Accuracy: 1.000\n",
      "KNORAE Accuracy: 1.000\n",
      "Accuracy total KNORAU: 1.000\n",
      "Accuracy total KNORAE: 1.000\n",
      ">LogisticRegression: 0.983\n",
      ">DecisionTreeClassifier: 0.966\n",
      ">GaussianNB: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset\n",
    "data = load_wine()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Definir nuevos clasificadores\n",
    "classifiers = [LogisticRegression(), DecisionTreeClassifier(), GaussianNB()]\n",
    "\n",
    "# Entrenar cada clasificador en train\n",
    "for c in classifiers:\n",
    "    c.fit(X_train, y_train)\n",
    "\n",
    "# Aplicar KNORAU\n",
    "knorau = KNORAU(pool_classifiers=classifiers)\n",
    "knorau.fit(X_train, y_train)\n",
    "pred_knorau = knorau.predict(X_test)\n",
    "score_knorau = accuracy_score(y_test, pred_knorau)\n",
    "print('KNORAU Accuracy: %.3f' % (score_knorau))\n",
    "\n",
    "# Aplicar KNORAE\n",
    "knorae = KNORAE(pool_classifiers=classifiers)\n",
    "knorae.fit(X_train, y_train)\n",
    "pred_knorae = knorae.predict(X_test)\n",
    "score_knorae = accuracy_score(y_test, pred_knorae)\n",
    "print('KNORAE Accuracy: %.3f' % (score_knorae))\n",
    "\n",
    "# Evaluar los modelos contribuyentes\n",
    "print('Accuracy total KNORAU: %.3f' % (score_knorau))\n",
    "print('Accuracy total KNORAE: %.3f' % (score_knorae))\n",
    "for c in classifiers:\n",
    "    pred = c.predict(X_test)\n",
    "    score = accuracy_score(y_test, pred)\n",
    "    print('>%s: %.3f' % (c.__class__.__name__, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 5</font>\n",
    "__Modelo contribuyente único__. Evalué otro modelo contribuyente único analizando todo lo relacionado a este."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNORAU Accuracy: 1.000\n",
      "KNORAE Accuracy: 1.000\n",
      "Accuracy total KNORAU: 1.000\n",
      "Accuracy total KNORAE: 1.000\n",
      ">LogisticRegression: 0.983\n",
      ">DecisionTreeClassifier: 0.949\n",
      ">GaussianNB: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset\n",
    "data = load_wine()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Definir nuevos clasificadores\n",
    "classifiers = [LogisticRegression(), DecisionTreeClassifier(), GaussianNB()]\n",
    "\n",
    "# Entrenar cada clasificador en train\n",
    "for c in classifiers:\n",
    "    c.fit(X_train, y_train)\n",
    "\n",
    "# Aplicar KNORAU\n",
    "knorau = KNORAU(pool_classifiers=classifiers)\n",
    "knorau.fit(X_train, y_train)\n",
    "pred_knorau = knorau.predict(X_test)\n",
    "score_knorau = accuracy_score(y_test, pred_knorau)\n",
    "print('KNORAU Accuracy: %.3f' % (score_knorau))\n",
    "\n",
    "# Aplicar KNORAE\n",
    "knorae = KNORAE(pool_classifiers=classifiers)\n",
    "knorae.fit(X_train, y_train)\n",
    "pred_knorae = knorae.predict(X_test)\n",
    "score_knorae = accuracy_score(y_test, pred_knorae)\n",
    "print('KNORAE Accuracy: %.3f' % (score_knorae))\n",
    "\n",
    "# Evaluar los modelos contribuyentes\n",
    "print('Accuracy total KNORAU: %.3f' % (score_knorau))\n",
    "print('Accuracy total KNORAE: %.3f' % (score_knorae))\n",
    "for c in classifiers:\n",
    "    pred = c.predict(X_test)\n",
    "    score = accuracy_score(y_test, pred)\n",
    "    print('>%s: %.3f' % (c.__class__.__name__, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#004D7F\" size=5>Ejercicio 6</font>\n",
    "__Más técnicas de DESlib__. DESlib es una librería que tiene muchas otras técnicas muy interesantes. Escoja 3 técnicas adicionales y desarróllas a imagen y semejanza de este cuaderno. También la parte teórica de los modelos que hayas seleccionado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Técnicas de DESlib\n",
    "\n",
    "La biblioteca **DESlib** (Dynamic Ensemble Selection Library) ofrece una variedad de técnicas avanzadas para la selección dinámica de clasificadores y conjuntos. Aquí tienes un resumen de las principales técnicas que permite:\n",
    "\n",
    "## Técnicas de Selección Dinámica de Clasificadores (DCS)\n",
    "\n",
    "1. **OLA (Overall Local Accuracy)**: Selecciona el clasificador con la mayor precisión local en la región de competencia.\n",
    "2. **A Priori**: Selecciona el clasificador basado en la precisión a priori en la región de competencia.\n",
    "3. **MCB (Multiple Classifier Behavior)**: Selecciona el clasificador basado en el comportamiento múltiple de los clasificadores en la región de competencia.\n",
    "\n",
    "## Técnicas de Selección Dinámica de Conjuntos (DES)\n",
    "\n",
    "1. **KNORA-Union (K-Nearest Oracles Union)**: Selecciona un conjunto de clasificadores que han clasificado correctamente al menos una muestra en la región de competencia.\n",
    "2. **KNORA-Eliminate (K-Nearest Oracles Eliminate)**: Selecciona un conjunto de clasificadores que han clasificado correctamente todas las muestras en la región de competencia.\n",
    "3. **DES-P (Dynamic Ensemble Selection Performance)**: Selecciona un conjunto de clasificadores basado en su rendimiento en la región de competencia.\n",
    "4. **META-DES**: Utiliza un meta-clasificador para seleccionar el mejor conjunto de clasificadores basado en características dinámicas.\n",
    "\n",
    "## Ejemplo de Uso\n",
    "\n",
    "Aquí tienes un ejemplo de cómo utilizar la técnica KNORA-Eliminate con un conjunto de clasificadores de RandomForest:\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from deslib.des.knora_e import KNORAE\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Cargar el dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Entrenar un conjunto de clasificadores\n",
    "pool_classifiers = RandomForestClassifier(n_estimators=10)\n",
    "pool_classifiers.fit(X_train, y_train)\n",
    "\n",
    "# Inicializar el modelo DES\n",
    "knorae = KNORAE(pool_classifiers)\n",
    "\n",
    "# Preprocesar el conjunto de datos de selección dinámica (DSEL)\n",
    "X_train, X_dsel, y_train, y_dsel = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
    "knorae.fit(X_dsel, y_dsel)\n",
    "\n",
    "# Predecir nuevas muestras\n",
    "y_pred = knorae.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
